{
  "scripts": [
    "#!/bin/bash\n# Batch user creation from CSV file\n# Usage: ./create_users.sh users.csv\n\nCSV_FILE=\"${1:-users.csv}\"\n\nif [ ! -f \"$CSV_FILE\" ]; then\n    echo \"Error: CSV file not found: $CSV_FILE\"\n    exit 1\nfi\n\nwhile IFS=, read -r username fullname email; do\n    # Skip header\n    if [ \"$username\" = \"username\" ]; then\n        continue\n    fi\n\n    echo \"Creating user: $username\"\n\n    # Create user\n    useradd -m -c \"$fullname\" \"$username\"\n\n    # Set default password (force change on first login)\n    echo \"$username:Change@123\" | chpasswd\n    chage -d 0 \"$username\"\n\n    echo \"User $username created successfully\"\ndone < \"$CSV_FILE\"\n\necho \"Batch user creation complete\"\n",
    "#!/bin/bash\n# Automated disk cleanup script\n# Removes old logs, temp files, and cached data\n\nLOG_DIRS=(\"/var/log\" \"/tmp\")\nDAYS_OLD=30\nDRY_RUN=false\n\nusage() {\n    echo \"Usage: $0 [-d days] [-n (dry-run)]\"\n    exit 1\n}\n\nwhile getopts \"d:n\" opt; do\n    case $opt in\n        d) DAYS_OLD=$OPTARG ;;\n        n) DRY_RUN=true ;;\n        *) usage ;;\n    esac\ndone\n\necho \"Disk Cleanup Script\"\necho \"===================\"\necho \"Cleaning files older than $DAYS_OLD days\"\necho \"Dry run: $DRY_RUN\"\necho\n\nfor dir in \"${LOG_DIRS[@]}\"; do\n    if [ -d \"$dir\" ]; then\n        echo \"Cleaning: $dir\"\n\n        if [ \"$DRY_RUN\" = true ]; then\n            find \"$dir\" -type f -mtime +$DAYS_OLD -print\n        else\n            find \"$dir\" -type f -mtime +$DAYS_OLD -delete\n        fi\n    fi\ndone\n\n# Clean package manager cache\nif [ \"$DRY_RUN\" = false ]; then\n    apt-get clean 2>/dev/null || yum clean all 2>/dev/null\nfi\n\necho \"Cleanup complete\"\ndf -h\n",
    "#!/bin/bash\n# Service health checker with email alerts\n\nSERVICES=(\"nginx\" \"mysql\" \"redis\")\nEMAIL=\"admin@example.com\"\nFAILED_SERVICES=()\n\ncheck_service() {\n    local service=$1\n\n    if systemctl is-active --quiet \"$service\"; then\n        echo \"\u2713 $service is running\"\n        return 0\n    else\n        echo \"\u2717 $service is NOT running\"\n        FAILED_SERVICES+=(\"$service\")\n        return 1\n    fi\n}\n\nrestart_service() {\n    local service=$1\n    echo \"Attempting to restart $service...\"\n\n    systemctl restart \"$service\"\n\n    if systemctl is-active --quiet \"$service\"; then\n        echo \"\u2713 $service restarted successfully\"\n        return 0\n    else\n        echo \"\u2717 Failed to restart $service\"\n        return 1\n    fi\n}\n\nsend_alert() {\n    local message=$1\n    echo \"$message\" | mail -s \"Service Alert\" \"$EMAIL\"\n}\n\necho \"Checking services...\"\n\nfor service in \"${SERVICES[@]}\"; do\n    if ! check_service \"$service\"; then\n        restart_service \"$service\" || {\n            send_alert \"$service failed and could not be restarted\"\n        }\n    fi\ndone\n\nif [ ${#FAILED_SERVICES[@]} -gt 0 ]; then\n    echo \"Failed services: ${FAILED_SERVICES[*]}\"\n    exit 1\nfi\n\necho \"All services healthy\"\n",
    "#!/bin/bash\n# Backup rotation script with retention policy\n\nBACKUP_DIR=\"/backup\"\nRETENTION_DAYS=7\nMONTHLY_KEEP=6\nYEARLY_KEEP=2\n\nrotate_backups() {\n    cd \"$BACKUP_DIR\" || exit 1\n\n    # Delete old daily backups\n    echo \"Removing daily backups older than $RETENTION_DAYS days...\"\n    find . -name \"daily_*.tar.gz\" -mtime +$RETENTION_DAYS -delete\n\n    # Keep monthly backups\n    echo \"Keeping $MONTHLY_KEEP monthly backups...\"\n    ls -t monthly_*.tar.gz 2>/dev/null | tail -n +$((MONTHLY_KEEP + 1)) | xargs rm -f\n\n    # Keep yearly backups\n    echo \"Keeping $YEARLY_KEEP yearly backups...\"\n    ls -t yearly_*.tar.gz 2>/dev/null | tail -n +$((YEARLY_KEEP + 1)) | xargs rm -f\n}\n\ncreate_backup() {\n    local type=$1\n    local filename=\"${type}_$(date +%Y%m%d_%H%M%S).tar.gz\"\n\n    echo \"Creating $type backup: $filename\"\n\n    tar -czf \"$BACKUP_DIR/$filename\" /data 2>/dev/null\n\n    if [ $? -eq 0 ]; then\n        echo \"Backup created successfully\"\n\n        # Generate checksum\n        cd \"$BACKUP_DIR\" && sha256sum \"$filename\" > \"$filename.sha256\"\n    else\n        echo \"Backup failed!\"\n        exit 1\n    fi\n}\n\n# Determine backup type based on date\nDAY=$(date +%d)\nMONTH=$(date +%m)\n\nif [ \"$DAY\" = \"01\" ] && [ \"$MONTH\" = \"01\" ]; then\n    create_backup \"yearly\"\nelif [ \"$DAY\" = \"01\" ]; then\n    create_backup \"monthly\"\nelse\n    create_backup \"daily\"\nfi\n\nrotate_backups\n\necho \"Backup and rotation complete\"\n",
    "#!/bin/bash\n# Automated system update with safety checks\n\nset -euo pipefail\n\nLOG_FILE=\"/var/log/system-update.log\"\nREBOOT_REQUIRED=\"/var/run/reboot-required\"\n\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $*\" | tee -a \"$LOG_FILE\"\n}\n\ncheck_disk_space() {\n    local available=$(df / | awk 'NR==2 {print $4}')\n    local required=1048576  # 1GB in KB\n\n    if [ \"$available\" -lt \"$required\" ]; then\n        log \"ERROR: Insufficient disk space\"\n        exit 1\n    fi\n}\n\nbackup_package_list() {\n    log \"Backing up package list...\"\n    dpkg --get-selections > /backup/package-list-$(date +%Y%m%d).txt\n}\n\nperform_update() {\n    log \"Starting system update...\"\n\n    # Update package lists\n    apt-get update\n\n    # Upgrade packages\n    apt-get upgrade -y\n\n    # Clean up\n    apt-get autoremove -y\n    apt-get autoclean\n\n    log \"Update complete\"\n}\n\ncheck_reboot() {\n    if [ -f \"$REBOOT_REQUIRED\" ]; then\n        log \"NOTICE: System reboot required\"\n\n        cat \"$REBOOT_REQUIRED\"\n\n        # Schedule reboot for 2 AM\n        echo \"shutdown -r 02:00 'Scheduled reboot for updates'\" | at now\n    fi\n}\n\nmain() {\n    log \"=== System Update Started ===\"\n\n    check_disk_space\n    backup_package_list\n    perform_update\n    check_reboot\n\n    log \"=== System Update Completed ===\"\n}\n\nmain \"$@\"\n",
    "#!/bin/bash\n# Custom log rotation script for application logs\n\nAPP_LOG_DIR=\"/var/log/myapp\"\nROTATE_DAYS=7\nCOMPRESS_AFTER_DAYS=1\nARCHIVE_DIR=\"/var/log/myapp/archive\"\n\nmkdir -p \"$ARCHIVE_DIR\"\n\nrotate_log() {\n    local logfile=$1\n    local basename=$(basename \"$logfile\")\n\n    if [ ! -f \"$logfile\" ]; then\n        return\n    fi\n\n    # Rotate if file exists and has content\n    if [ -s \"$logfile\" ]; then\n        local timestamp=$(date +%Y%m%d_%H%M%S)\n        local rotated=\"${ARCHIVE_DIR}/${basename}.${timestamp}\"\n\n        echo \"Rotating: $logfile -> $rotated\"\n        cp \"$logfile\" \"$rotated\"\n        > \"$logfile\"\n\n        # Compress old rotated logs\n        find \"$ARCHIVE_DIR\" -name \"${basename}.*\" -mtime +$COMPRESS_AFTER_DAYS ! -name \"*.gz\" -exec gzip {} \\;\n\n        # Delete old archives\n        find \"$ARCHIVE_DIR\" -name \"${basename}.*.gz\" -mtime +$ROTATE_DAYS -delete\n    fi\n}\n\n# Rotate all application logs\nfor logfile in \"$APP_LOG_DIR\"/*.log; do\n    rotate_log \"$logfile\"\ndone\n\necho \"Log rotation complete\"\n",
    "#!/bin/bash\n# SSL certificate expiration checker\n\nDOMAINS=(\"example.com\" \"api.example.com\" \"www.example.com\")\nWARNING_DAYS=30\nALERT_EMAIL=\"admin@example.com\"\n\ncheck_cert() {\n    local domain=$1\n\n    echo \"Checking certificate for $domain...\"\n\n    # Get expiration date\n    expiry=$(echo | openssl s_client -servername \"$domain\" -connect \"$domain:443\" 2>/dev/null |              openssl x509 -noout -enddate 2>/dev/null | cut -d= -f2)\n\n    if [ -z \"$expiry\" ]; then\n        echo \"ERROR: Could not retrieve certificate for $domain\"\n        return 1\n    fi\n\n    # Calculate days until expiration\n    expiry_epoch=$(date -d \"$expiry\" +%s 2>/dev/null || date -j -f \"%b %d %H:%M:%S %Y %Z\" \"$expiry\" +%s)\n    current_epoch=$(date +%s)\n    days_left=$(( ($expiry_epoch - $current_epoch) / 86400 ))\n\n    echo \"  Expires: $expiry\"\n    echo \"  Days left: $days_left\"\n\n    if [ $days_left -lt 0 ]; then\n        echo \"  STATUS: EXPIRED\"\n        echo \"$domain certificate has EXPIRED!\" | mail -s \"SSL ALERT: Certificate Expired\" \"$ALERT_EMAIL\"\n        return 1\n    elif [ $days_left -lt $WARNING_DAYS ]; then\n        echo \"  STATUS: WARNING\"\n        echo \"$domain certificate expires in $days_left days\" | mail -s \"SSL WARNING: Certificate Expiring Soon\" \"$ALERT_EMAIL\"\n        return 1\n    else\n        echo \"  STATUS: OK\"\n        return 0\n    fi\n}\n\necho \"SSL Certificate Check\"\necho \"=====================\"\necho\n\nISSUES=0\n\nfor domain in \"${DOMAINS[@]}\"; do\n    check_cert \"$domain\" || ((ISSUES++))\n    echo\ndone\n\nif [ $ISSUES -gt 0 ]; then\n    echo \"Certificate issues detected: $ISSUES\"\n    exit 1\nelse\n    echo \"All certificates OK\"\n    exit 0\nfi\n",
    "#!/bin/bash\n# Check and enforce file system quotas\n\nQUOTA_LIMIT_GB=100\nWARNING_THRESHOLD=80  # percentage\n\ncheck_user_quota() {\n    local user=$1\n\n    # Get user's home directory usage\n    local usage=$(du -sh \"/home/$user\" 2>/dev/null | awk '{print $1}')\n    local usage_gb=$(du -sb \"/home/$user\" 2>/dev/null | awk '{print int($1/1024/1024/1024)}')\n\n    echo \"User: $user\"\n    echo \"  Usage: $usage ($usage_gb GB)\"\n\n    # Check if over quota\n    if [ \"$usage_gb\" -gt \"$QUOTA_LIMIT_GB\" ]; then\n        echo \"  STATUS: OVER QUOTA\"\n        echo \"User $user is over quota: ${usage_gb}GB / ${QUOTA_LIMIT_GB}GB\" |             mail -s \"Quota Alert\" \"${user}@localhost\"\n        return 1\n    fi\n\n    # Check if approaching quota\n    local percent=$(( usage_gb * 100 / QUOTA_LIMIT_GB ))\n    if [ \"$percent\" -gt \"$WARNING_THRESHOLD\" ]; then\n        echo \"  STATUS: WARNING (${percent}% used)\"\n        echo \"You are using ${percent}% of your quota\" |             mail -s \"Quota Warning\" \"${user}@localhost\"\n    else\n        echo \"  STATUS: OK (${percent}% used)\"\n    fi\n\n    return 0\n}\n\necho \"File System Quota Check\"\necho \"=======================\"\necho \"Quota Limit: ${QUOTA_LIMIT_GB}GB\"\necho\n\n# Check all regular users\nfor user in $(getent passwd | awk -F: '$3 >= 1000 && $3 < 65000 {print $1}'); do\n    if [ -d \"/home/$user\" ]; then\n        check_user_quota \"$user\"\n        echo\n    fi\ndone\n",
    "#!/bin/bash\n# Detect and handle zombie processes\n\necho \"Zombie Process Hunter\"\necho \"====================\"\n\n# Find zombie processes\nZOMBIES=$(ps aux | awk '$8==\"Z\" {print $2}')\n\nif [ -z \"$ZOMBIES\" ]; then\n    echo \"No zombie processes found\"\n    exit 0\nfi\n\necho \"Found zombie processes:\"\nps aux | awk '$8==\"Z\" {print}'\n\necho\necho \"Zombie PIDs: $ZOMBIES\"\n\n# For each zombie, try to clean up by signaling parent\nfor zpid in $ZOMBIES; do\n    # Get parent PID\n    PPID=$(ps -o ppid= -p \"$zpid\" 2>/dev/null | tr -d ' ')\n\n    if [ -n \"$PPID\" ] && [ \"$PPID\" != \"1\" ]; then\n        echo \"Sending SIGCHLD to parent process $PPID\"\n        kill -CHLD \"$PPID\" 2>/dev/null\n\n        sleep 1\n\n        # Check if zombie still exists\n        if ps -p \"$zpid\" > /dev/null 2>&1; then\n            echo \"Warning: Zombie $zpid still exists, parent may need restart\"\n            PARENT_CMD=$(ps -p \"$PPID\" -o comm= 2>/dev/null)\n            echo \"  Parent process: $PPID ($PARENT_CMD)\"\n        else\n            echo \"Successfully cleaned zombie $zpid\"\n        fi\n    fi\ndone\n",
    "#!/bin/bash\n# Validate and test cron jobs\n\nCRON_DIR=\"/var/spool/cron/crontabs\"\nTEST_MODE=\"${1:-check}\"\n\nvalidate_cron_syntax() {\n    local cronline=$1\n\n    # Skip comments and empty lines\n    if [[ \"$cronline\" =~ ^#.*$ ]] || [ -z \"$cronline\" ]; then\n        return 0\n    fi\n\n    # Basic validation\n    if [[ ! \"$cronline\" =~ ^[0-9\\*,\\-/]+ ]]; then\n        echo \"  \u2717 Invalid syntax: $cronline\"\n        return 1\n    fi\n\n    echo \"  \u2713 Valid syntax: $cronline\"\n    return 0\n}\n\ncheck_command_exists() {\n    local cronline=$1\n    local cmd=$(echo \"$cronline\" | awk '{for(i=6;i<=NF;i++) printf \"%s \", $i}' | awk '{print $1}')\n\n    if [ -n \"$cmd\" ] && ! command -v \"$cmd\" &> /dev/null; then\n        echo \"  \u26a0 Command not found: $cmd\"\n        return 1\n    fi\n\n    return 0\n}\n\nvalidate_user_crontab() {\n    local user=$1\n    local cronfile=\"$CRON_DIR/$user\"\n\n    if [ ! -f \"$cronfile\" ]; then\n        return 0\n    fi\n\n    echo \"Validating crontab for user: $user\"\n    echo \"==================================\"\n\n    local issues=0\n\n    while IFS= read -r line; do\n        validate_cron_syntax \"$line\" || ((issues++))\n        check_command_exists \"$line\" || ((issues++))\n    done < \"$cronfile\"\n\n    if [ $issues -eq 0 ]; then\n        echo \"\u2713 No issues found\"\n    else\n        echo \"\u2717 Found $issues issue(s)\"\n    fi\n\n    echo\n    return $issues\n}\n\necho \"Cron Job Validator\"\necho \"==================\"\necho\n\ntotal_issues=0\n\n# Check system crontab\nif [ -f /etc/crontab ]; then\n    echo \"Checking /etc/crontab\"\n    validate_cron_syntax \"$(cat /etc/crontab)\"\nfi\n\n# Check user crontabs\nfor user in $(ls \"$CRON_DIR\" 2>/dev/null); do\n    validate_user_crontab \"$user\"\n    total_issues=$((total_issues + $?))\ndone\n\nif [ $total_issues -gt 0 ]; then\n    echo \"Total issues found: $total_issues\"\n    exit 1\nelse\n    echo \"All cron jobs validated successfully\"\n    exit 0\nfi\n",
    "#!/bin/bash\n# Create system performance baseline\n\nOUTPUT_FILE=\"/var/log/performance-baseline-$(date +%Y%m%d).log\"\n\n{\n    echo \"System Performance Baseline\"\n    echo \"===========================\"\n    echo \"Date: $(date)\"\n    echo \"Hostname: $(hostname)\"\n    echo\n\n    echo \"=== CPU Information ===\"\n    lscpu | grep -E \"Model name|CPU\\(s\\)|MHz|Cache\"\n    echo\n\n    echo \"=== Memory Information ===\"\n    free -h\n    echo\n\n    echo \"=== Disk Information ===\"\n    df -h\n    echo\n\n    echo \"=== Disk I/O ===\"\n    iostat -x 1 5\n    echo\n\n    echo \"=== Network Interfaces ===\"\n    ip addr show\n    echo\n\n    echo \"=== Load Average ===\"\n    uptime\n    echo\n\n    echo \"=== Top 10 CPU Processes ===\"\n    ps aux --sort=-%cpu | head -11\n    echo\n\n    echo \"=== Top 10 Memory Processes ===\"\n    ps aux --sort=-%mem | head -11\n    echo\n\n    echo \"=== Network Connections ===\"\n    ss -s\n    echo\n\n    echo \"=== System Limits ===\"\n    ulimit -a\n\n} | tee \"$OUTPUT_FILE\"\n\necho\necho \"Baseline saved to: $OUTPUT_FILE\"\n",
    "#!/bin/bash\n# Find and optionally remove broken symbolic links\n\nSEARCH_DIR=\"${1:-.}\"\nDELETE=false\n\nusage() {\n    echo \"Usage: $0 [directory] [-d]\"\n    echo \"  -d: Delete broken symlinks\"\n    exit 1\n}\n\nwhile getopts \"d\" opt; do\n    case $opt in\n        d) DELETE=true ;;\n        *) usage ;;\n    esac\ndone\n\necho \"Searching for broken symlinks in: $SEARCH_DIR\"\necho \"Delete mode: $DELETE\"\necho\n\nBROKEN_LINKS=()\n\n# Find all symlinks\nwhile IFS= read -r link; do\n    # Check if target exists\n    if [ ! -e \"$link\" ]; then\n        BROKEN_LINKS+=(\"$link\")\n        echo \"Broken: $link -> $(readlink \"$link\")\"\n\n        if [ \"$DELETE\" = true ]; then\n            rm \"$link\"\n            echo \"  Deleted\"\n        fi\n    fi\ndone < <(find \"$SEARCH_DIR\" -type l 2>/dev/null)\n\necho\necho \"Found ${#BROKEN_LINKS[@]} broken symlink(s)\"\n\nif [ \"$DELETE\" = false ] && [ ${#BROKEN_LINKS[@]} -gt 0 ]; then\n    echo \"Run with -d to delete broken symlinks\"\nfi\n",
    "#!/bin/bash\n# Find largest files and directories\n\nSEARCH_DIR=\"${1:-.}\"\nTOP_N=\"${2:-10}\"\n\necho \"Finding top $TOP_N largest files in: $SEARCH_DIR\"\necho \"==================================================\"\necho\n\necho \"Largest Files:\"\necho \"-------------\"\nfind \"$SEARCH_DIR\" -type f -exec du -h {} + 2>/dev/null |     sort -rh | head -n \"$TOP_N\" |     awk '{printf \"%-10s %s\n\", $1, $2}'\n\necho\necho \"Largest Directories:\"\necho \"-------------------\"\ndu -h \"$SEARCH_DIR\"/* 2>/dev/null |     sort -rh | head -n \"$TOP_N\" |     awk '{printf \"%-10s %s\n\", $1, $2}'\n\necho\necho \"Disk Usage Summary:\"\necho \"------------------\"\ndf -h \"$SEARCH_DIR\"\n",
    "#!/bin/bash\n# Audit file permissions for security issues\n\nSEARCH_DIR=\"${1:-/}\"\nREPORT_FILE=\"/tmp/permission-audit-$(date +%Y%m%d).txt\"\n\n{\n    echo \"File Permission Security Audit\"\n    echo \"==============================\"\n    echo \"Date: $(date)\"\n    echo \"Search directory: $SEARCH_DIR\"\n    echo\n\n    echo \"=== World-Writable Files ===\"\n    find \"$SEARCH_DIR\" -type f -perm -002 ! -path \"*/proc/*\" ! -path \"*/sys/*\" 2>/dev/null\n\n    echo\n    echo \"=== World-Writable Directories ===\"\n    find \"$SEARCH_DIR\" -type d -perm -002 ! -path \"*/proc/*\" ! -path \"*/sys/*\" 2>/dev/null\n\n    echo\n    echo \"=== SUID Files ===\"\n    find \"$SEARCH_DIR\" -type f -perm -4000 ! -path \"*/proc/*\" 2>/dev/null\n\n    echo\n    echo \"=== SGID Files ===\"\n    find \"$SEARCH_DIR\" -type f -perm -2000 ! -path \"*/proc/*\" 2>/dev/null\n\n    echo\n    echo \"=== Files Without Owner ===\"\n    find \"$SEARCH_DIR\" -nouser ! -path \"*/proc/*\" ! -path \"*/sys/*\" 2>/dev/null\n\n    echo\n    echo \"=== Files Without Group ===\"\n    find \"$SEARCH_DIR\" -nogroup ! -path \"*/proc/*\" ! -path \"*/sys/*\" 2>/dev/null\n\n} | tee \"$REPORT_FILE\"\n\necho\necho \"Audit report saved to: $REPORT_FILE\"\n",
    "#!/bin/bash\n# Monitor network interface statistics\n\nINTERFACE=\"${1:-eth0}\"\nINTERVAL=\"${2:-5}\"\n\nif ! ip link show \"$INTERFACE\" &>/dev/null; then\n    echo \"Error: Interface $INTERFACE not found\"\n    exit 1\nfi\n\necho \"Monitoring interface: $INTERFACE\"\necho \"Sample interval: ${INTERVAL}s\"\necho \"Press Ctrl+C to stop\"\necho\n\nget_stats() {\n    local iface=$1\n    local rx_bytes=$(cat \"/sys/class/net/$iface/statistics/rx_bytes\")\n    local tx_bytes=$(cat \"/sys/class/net/$iface/statistics/tx_bytes\")\n    local rx_packets=$(cat \"/sys/class/net/$iface/statistics/rx_packets\")\n    local tx_packets=$(cat \"/sys/class/net/$iface/statistics/tx_packets\")\n    local rx_errors=$(cat \"/sys/class/net/$iface/statistics/rx_errors\")\n    local tx_errors=$(cat \"/sys/class/net/$iface/statistics/tx_errors\")\n\n    echo \"$rx_bytes $tx_bytes $rx_packets $tx_packets $rx_errors $tx_errors\"\n}\n\nformat_bytes() {\n    local bytes=$1\n    if [ $bytes -gt 1073741824 ]; then\n        echo \"$(awk \"BEGIN {printf \"%.2f\", $bytes/1073741824}\") GB/s\"\n    elif [ $bytes -gt 1048576 ]; then\n        echo \"$(awk \"BEGIN {printf \"%.2f\", $bytes/1048576}\") MB/s\"\n    elif [ $bytes -gt 1024 ]; then\n        echo \"$(awk \"BEGIN {printf \"%.2f\", $bytes/1024}\") KB/s\"\n    else\n        echo \"$bytes B/s\"\n    fi\n}\n\n# Initial reading\nread rx_bytes_old tx_bytes_old rx_pkts_old tx_pkts_old rx_err_old tx_err_old <<< $(get_stats \"$INTERFACE\")\n\nwhile true; do\n    sleep \"$INTERVAL\"\n\n    read rx_bytes_new tx_bytes_new rx_pkts_new tx_pkts_new rx_err_new tx_err_new <<< $(get_stats \"$INTERFACE\")\n\n    # Calculate deltas\n    rx_rate=$(( (rx_bytes_new - rx_bytes_old) / INTERVAL ))\n    tx_rate=$(( (tx_bytes_new - tx_bytes_old) / INTERVAL ))\n    rx_pps=$(( (rx_pkts_new - rx_pkts_old) / INTERVAL ))\n    tx_pps=$(( (tx_pkts_new - tx_pkts_old) / INTERVAL ))\n\n    echo \"$(date '+%H:%M:%S') | RX: $(format_bytes $rx_rate) ($rx_pps pps) | TX: $(format_bytes $tx_rate) ($tx_pps pps) | Errors: RX=$rx_err_new TX=$tx_err_new\"\n\n    # Update old values\n    rx_bytes_old=$rx_bytes_new\n    tx_bytes_old=$tx_bytes_new\n    rx_pkts_old=$rx_pkts_new\n    tx_pkts_old=$tx_pkts_new\ndone\n",
    "#!/bin/bash\n# Check system security hardening status\n\necho \"System Security Hardening Check\"\necho \"===============================\"\necho\n\nISSUES=0\n\ncheck_item() {\n    local description=$1\n    local command=$2\n    local expected=$3\n\n    echo -n \"Checking: $description... \"\n\n    result=$(eval \"$command\" 2>/dev/null)\n\n    if [ \"$result\" = \"$expected\" ]; then\n        echo \"\u2713 PASS\"\n        return 0\n    else\n        echo \"\u2717 FAIL (got: $result, expected: $expected)\"\n        ((ISSUES++))\n        return 1\n    fi\n}\n\n# Check SSH hardening\necho \"=== SSH Configuration ===\"\ncheck_item \"Root login disabled\" \"grep -E '^PermitRootLogin' /etc/ssh/sshd_config | awk '{print \\$2}'\" \"no\"\ncheck_item \"Password auth disabled\" \"grep -E '^PasswordAuthentication' /etc/ssh/sshd_config | awk '{print \\$2}'\" \"no\"\ncheck_item \"SSH protocol 2\" \"grep -E '^Protocol' /etc/ssh/sshd_config | awk '{print \\$2}'\" \"2\"\necho\n\n# Check firewall\necho \"=== Firewall ===\"\nif command -v ufw &>/dev/null; then\n    check_item \"UFW enabled\" \"ufw status | head -1 | awk '{print \\$2}'\" \"active\"\nelif command -v firewall-cmd &>/dev/null; then\n    check_item \"Firewalld running\" \"systemctl is-active firewalld\" \"active\"\nelse\n    echo \"\u2717 No firewall detected\"\n    ((ISSUES++))\nfi\necho\n\n# Check automatic updates\necho \"=== Automatic Updates ===\"\nif [ -f /etc/apt/apt.conf.d/20auto-upgrades ]; then\n    check_item \"Auto updates enabled\" \"grep -c '^APT::Periodic::Update-Package-Lists \"1\"' /etc/apt/apt.conf.d/20auto-upgrades\" \"1\"\nelse\n    echo \"\u2717 Auto updates not configured\"\n    ((ISSUES++))\nfi\necho\n\n# Check system limits\necho \"=== System Limits ===\"\ncheck_item \"Core dumps disabled\" \"grep -c '* hard core 0' /etc/security/limits.conf\" \"1\"\necho\n\n# Summary\necho \"===============================\"\nif [ $ISSUES -eq 0 ]; then\n    echo \"\u2713 All checks passed\"\n    exit 0\nelse\n    echo \"\u2717 Found $ISSUES security issue(s)\"\n    exit 1\nfi\n",
    "#!/bin/bash\n# Check service dependencies and start order\n\nSERVICE=\"${1:-nginx}\"\n\nif [ -z \"$SERVICE\" ]; then\n    echo \"Usage: $0 <service-name>\"\n    exit 1\nfi\n\necho \"Service Dependency Analysis: $SERVICE\"\necho \"=====================================\"\necho\n\n# Get service file\nSERVICE_FILE=$(systemctl show -p FragmentPath \"$SERVICE\" | cut -d= -f2)\n\nif [ ! -f \"$SERVICE_FILE\" ]; then\n    echo \"Error: Service file not found for $SERVICE\"\n    exit 1\nfi\n\necho \"Service file: $SERVICE_FILE\"\necho\n\n# Parse dependencies\necho \"=== Dependencies ===\"\necho \"After:\"\ngrep \"^After=\" \"$SERVICE_FILE\" | cut -d= -f2 | tr ' ' '\n' | sed 's/^/  - /'\n\necho\necho \"Requires:\"\ngrep \"^Requires=\" \"$SERVICE_FILE\" | cut -d= -f2 | tr ' ' '\n' | sed 's/^/  - /'\n\necho\necho \"Wants:\"\ngrep \"^Wants=\" \"$SERVICE_FILE\" | cut -d= -f2 | tr ' ' '\n' | sed 's/^/  - /'\n\necho\necho \"=== Dependents (services that depend on this) ===\"\nfor unit in /etc/systemd/system/*.service /lib/systemd/system/*.service; do\n    if [ -f \"$unit\" ]; then\n        if grep -q \"$SERVICE\" \"$unit\" 2>/dev/null; then\n            echo \"  - $(basename \"$unit\")\"\n        fi\n    fi\ndone\n\necho\necho \"=== Current Status ===\"\nsystemctl status \"$SERVICE\" --no-pager\n",
    "#!/bin/bash\n# Check available system patches and security updates\n\necho \"System Patch Status\"\necho \"===================\"\necho \"Date: $(date)\"\necho\n\n# Detect package manager\nif command -v apt-get &>/dev/null; then\n    PKG_MGR=\"apt\"\nelif command -v yum &>/dev/null; then\n    PKG_MGR=\"yum\"\nelse\n    echo \"Error: Unsupported package manager\"\n    exit 1\nfi\n\nupdate_cache() {\n    echo \"Updating package cache...\"\n    if [ \"$PKG_MGR\" = \"apt\" ]; then\n        apt-get update -qq\n    else\n        yum check-update -q\n    fi\n}\n\ncheck_updates() {\n    echo\n    echo \"=== Available Updates ===\"\n\n    if [ \"$PKG_MGR\" = \"apt\" ]; then\n        TOTAL=$(apt list --upgradable 2>/dev/null | grep -c upgradable)\n        SECURITY=$(apt list --upgradable 2>/dev/null | grep -i security | wc -l)\n\n        echo \"Total updates available: $TOTAL\"\n        echo \"Security updates: $SECURITY\"\n        echo\n\n        if [ $SECURITY -gt 0 ]; then\n            echo \"Security Updates:\"\n            apt list --upgradable 2>/dev/null | grep -i security\n        fi\n    else\n        TOTAL=$(yum list updates 2>/dev/null | grep -v \"^Loaded\" | grep -v \"^Updated\" | wc -l)\n        SECURITY=$(yum list-security 2>/dev/null | grep -i security | wc -l)\n\n        echo \"Total updates available: $TOTAL\"\n        echo \"Security updates: $SECURITY\"\n    fi\n}\n\ncheck_reboot_required() {\n    echo\n    echo \"=== Reboot Status ===\"\n\n    if [ -f /var/run/reboot-required ]; then\n        echo \"\u26a0 System reboot required\"\n        if [ -f /var/run/reboot-required.pkgs ]; then\n            echo \"Packages requiring reboot:\"\n            cat /var/run/reboot-required.pkgs\n        fi\n    else\n        echo \"\u2713 No reboot required\"\n    fi\n}\n\nlast_update() {\n    echo\n    echo \"=== Last Update ===\"\n\n    if [ \"$PKG_MGR\" = \"apt\" ]; then\n        LAST=$(stat -c %y /var/lib/apt/periodic/update-success-stamp 2>/dev/null || echo \"Unknown\")\n    else\n        LAST=$(stat -c %y /var/cache/yum 2>/dev/null || echo \"Unknown\")\n    fi\n\n    echo \"Last update check: $LAST\"\n}\n\nupdate_cache\ncheck_updates\ncheck_reboot_required\nlast_update\n\necho\necho \"===================\"\necho \"Patch check complete\"\n",
    "#!/bin/bash\n# Monitor critical system files for changes\n\nWATCH_DIRS=(\"/etc\" \"/boot\" \"/usr/bin\")\nBASELINE_FILE=\"/var/lib/fim/baseline.db\"\nREPORT_FILE=\"/var/lib/fim/changes-$(date +%Y%m%d_%H%M%S).txt\"\n\nmkdir -p \"$(dirname \"$BASELINE_FILE\")\"\n\ncreate_baseline() {\n    echo \"Creating baseline...\"\n\n    {\n        for dir in \"${WATCH_DIRS[@]}\"; do\n            find \"$dir\" -type f -exec sha256sum {} \\; 2>/dev/null\n        done\n    } > \"$BASELINE_FILE\"\n\n    echo \"Baseline created: $BASELINE_FILE\"\n    echo \"Total files: $(wc -l < \"$BASELINE_FILE\")\"\n}\n\ncheck_integrity() {\n    if [ ! -f \"$BASELINE_FILE\" ]; then\n        echo \"Error: No baseline found. Run with --create-baseline first\"\n        exit 1\n    fi\n\n    echo \"Checking file integrity...\"\n    echo \"==========================\" > \"$REPORT_FILE\"\n\n    CHANGES=0\n    ADDED=0\n    REMOVED=0\n    MODIFIED=0\n\n    # Create current snapshot\n    TEMP_SNAPSHOT=\"/tmp/fim-snapshot-$$.db\"\n    {\n        for dir in \"${WATCH_DIRS[@]}\"; do\n            find \"$dir\" -type f -exec sha256sum {} \\; 2>/dev/null\n        done\n    } > \"$TEMP_SNAPSHOT\"\n\n    # Compare with baseline\n    echo \"Modified files:\" >> \"$REPORT_FILE\"\n    while IFS= read -r line; do\n        hash=$(echo \"$line\" | awk '{print $1}')\n        file=$(echo \"$line\" | cut -d' ' -f3-)\n\n        baseline_hash=$(grep \" $file$\" \"$BASELINE_FILE\" | awk '{print $1}')\n\n        if [ -z \"$baseline_hash\" ]; then\n            echo \"  [ADDED] $file\" >> \"$REPORT_FILE\"\n            ((ADDED++))\n            ((CHANGES++))\n        elif [ \"$hash\" != \"$baseline_hash\" ]; then\n            echo \"  [MODIFIED] $file\" >> \"$REPORT_FILE\"\n            ((MODIFIED++))\n            ((CHANGES++))\n        fi\n    done < \"$TEMP_SNAPSHOT\"\n\n    # Check for removed files\n    echo >> \"$REPORT_FILE\"\n    echo \"Removed files:\" >> \"$REPORT_FILE\"\n    while IFS= read -r line; do\n        file=$(echo \"$line\" | cut -d' ' -f3-)\n\n        if ! grep -q \" $file$\" \"$TEMP_SNAPSHOT\"; then\n            echo \"  [REMOVED] $file\" >> \"$REPORT_FILE\"\n            ((REMOVED++))\n            ((CHANGES++))\n        fi\n    done < \"$BASELINE_FILE\"\n\n    # Summary\n    echo >> \"$REPORT_FILE\"\n    echo \"Summary:\" >> \"$REPORT_FILE\"\n    echo \"  Added: $ADDED\" >> \"$REPORT_FILE\"\n    echo \"  Modified: $MODIFIED\" >> \"$REPORT_FILE\"\n    echo \"  Removed: $REMOVED\" >> \"$REPORT_FILE\"\n    echo \"  Total changes: $CHANGES\" >> \"$REPORT_FILE\"\n\n    cat \"$REPORT_FILE\"\n\n    rm -f \"$TEMP_SNAPSHOT\"\n\n    if [ $CHANGES -gt 0 ]; then\n        echo\n        echo \"\u26a0 Changes detected! Report: $REPORT_FILE\"\n        exit 1\n    else\n        echo\n        echo \"\u2713 No changes detected\"\n        rm -f \"$REPORT_FILE\"\n        exit 0\n    fi\n}\n\ncase \"${1:-check}\" in\n    --create-baseline)\n        create_baseline\n        ;;\n    --check|check)\n        check_integrity\n        ;;\n    *)\n        echo \"Usage: $0 [--create-baseline|--check]\"\n        exit 1\n        ;;\nesac\n",
    "#!/bin/bash\n# Set and manage system resource limits for users/processes\n\nUSER=\"${1}\"\nLIMIT_TYPE=\"${2}\"\nLIMIT_VALUE=\"${3}\"\n\nusage() {\n    echo \"Usage: $0 <user|@group> <limit-type> <value>\"\n    echo\n    echo \"Limit types:\"\n    echo \"  cpu      - CPU time (minutes)\"\n    echo \"  mem      - Memory (MB)\"\n    echo \"  nproc    - Number of processes\"\n    echo \"  nofile   - Number of open files\"\n    echo \"  fsize    - File size (MB)\"\n    echo\n    echo \"Examples:\"\n    echo \"  $0 john cpu 60        # Limit john to 60 min CPU time\"\n    echo \"  $0 @users mem 1024    # Limit users group to 1GB RAM\"\n    exit 1\n}\n\nif [ $# -lt 3 ]; then\n    usage\nfi\n\nLIMITS_FILE=\"/etc/security/limits.conf\"\nBACKUP_FILE=\"/etc/security/limits.conf.backup-$(date +%Y%m%d)\"\n\n# Backup current limits\nif [ ! -f \"$BACKUP_FILE\" ]; then\n    cp \"$LIMITS_FILE\" \"$BACKUP_FILE\"\n    echo \"Backed up limits to: $BACKUP_FILE\"\nfi\n\nset_limit() {\n    local user=$1\n    local type=$2\n    local value=$3\n\n    # Remove existing limits for this user/type\n    sed -i \"/$user.*$type/d\" \"$LIMITS_FILE\"\n\n    # Add new limits\n    case $type in\n        cpu)\n            echo \"$user hard cpu $value\" >> \"$LIMITS_FILE\"\n            echo \"$user soft cpu $((value * 80 / 100))\" >> \"$LIMITS_FILE\"\n            ;;\n        mem)\n            # Convert MB to KB\n            local kb=$((value * 1024))\n            echo \"$user hard rss $kb\" >> \"$LIMITS_FILE\"\n            echo \"$user soft rss $((kb * 80 / 100))\" >> \"$LIMITS_FILE\"\n            ;;\n        nproc)\n            echo \"$user hard nproc $value\" >> \"$LIMITS_FILE\"\n            echo \"$user soft nproc $((value * 80 / 100))\" >> \"$LIMITS_FILE\"\n            ;;\n        nofile)\n            echo \"$user hard nofile $value\" >> \"$LIMITS_FILE\"\n            echo \"$user soft nofile $((value * 80 / 100))\" >> \"$LIMITS_FILE\"\n            ;;\n        fsize)\n            # Convert MB to KB\n            local kb=$((value * 1024))\n            echo \"$user hard fsize $kb\" >> \"$LIMITS_FILE\"\n            echo \"$user soft fsize $((kb * 80 / 100))\" >> \"$LIMITS_FILE\"\n            ;;\n        *)\n            echo \"Error: Unknown limit type: $type\"\n            return 1\n            ;;\n    esac\n\n    echo \"\u2713 Set $type limit for $user to $value\"\n}\n\nset_limit \"$USER\" \"$LIMIT_TYPE\" \"$LIMIT_VALUE\"\n\necho\necho \"Current limits for $USER:\"\ngrep \"^$USER\" \"$LIMITS_FILE\"\n\necho\necho \"Note: Users need to log out and back in for changes to take effect\"\n",
    "#!/bin/bash\n# Docker system cleanup script\n\necho \"Docker System Cleanup\"\necho \"====================\"\n\n# Remove stopped containers\necho \"Removing stopped containers...\"\ndocker container prune -f\n\n# Remove dangling images\necho \"Removing dangling images...\"\ndocker image prune -f\n\n# Remove unused volumes\necho \"Removing unused volumes...\"\ndocker volume prune -f\n\n# Remove unused networks\necho \"Removing unused networks...\"\ndocker network prune -f\n\n# Show disk usage\necho\necho \"Current disk usage:\"\ndocker system df\n\necho\necho \"Cleanup complete\"\n",
    "#!/bin/bash\n# Automated git deployment script\n\nREPO_URL=\"${1:-}\"\nDEPLOY_DIR=\"/var/www/app\"\nBRANCH=\"${2:-main}\"\n\nif [ -z \"$REPO_URL\" ]; then\n    echo \"Usage: $0 <repo-url> [branch]\"\n    exit 1\nfi\n\ndeploy() {\n    echo \"Deploying from $REPO_URL (branch: $BRANCH)\"\n\n    if [ -d \"$DEPLOY_DIR/.git\" ]; then\n        cd \"$DEPLOY_DIR\"\n        git fetch origin\n        git reset --hard \"origin/$BRANCH\"\n    else\n        git clone -b \"$BRANCH\" \"$REPO_URL\" \"$DEPLOY_DIR\"\n    fi\n\n    cd \"$DEPLOY_DIR\"\n\n    # Install dependencies\n    if [ -f \"package.json\" ]; then\n        npm install --production\n    elif [ -f \"requirements.txt\" ]; then\n        pip install -r requirements.txt\n    fi\n\n    # Restart service\n    systemctl restart app\n\n    echo \"Deployment complete\"\n}\n\n# Backup current deployment\nif [ -d \"$DEPLOY_DIR\" ]; then\n    cp -r \"$DEPLOY_DIR\" \"$DEPLOY_DIR.backup.$(date +%Y%m%d_%H%M%S)\"\nfi\n\ndeploy || {\n    echo \"Deployment failed!\"\n    if [ -d \"$DEPLOY_DIR.backup.\"* ]; then\n        echo \"Restoring backup...\"\n        rm -rf \"$DEPLOY_DIR\"\n        mv \"$DEPLOY_DIR.backup.\"* \"$DEPLOY_DIR\"\n    fi\n    exit 1\n}\n",
    "#!/bin/bash\n# Simple CI build runner\n\nset -e\n\nPROJECT_DIR=\"${1:-.}\"\nBUILD_LOG=\"build-$(date +%Y%m%d_%H%M%S).log\"\n\ncd \"$PROJECT_DIR\"\n\n{\n    echo \"=== CI Build Started ===\"\n    echo \"Date: $(date)\"\n    echo \"Branch: $(git branch --show-current)\"\n    echo \"Commit: $(git rev-parse --short HEAD)\"\n    echo\n\n    echo \"=== Installing Dependencies ===\"\n    if [ -f \"package.json\" ]; then\n        npm ci\n    elif [ -f \"requirements.txt\" ]; then\n        pip install -r requirements.txt\n    elif [ -f \"Gemfile\" ]; then\n        bundle install\n    fi\n\n    echo\n    echo \"=== Running Linter ===\"\n    if [ -f \".eslintrc.json\" ]; then\n        npm run lint\n    elif [ -f \".pylintrc\" ]; then\n        pylint src/\n    fi\n\n    echo\n    echo \"=== Running Tests ===\"\n    if [ -f \"package.json\" ] && grep -q \"test\" package.json; then\n        npm test\n    elif [ -f \"pytest.ini\" ]; then\n        pytest\n    elif [ -f \"Rakefile\" ]; then\n        rake test\n    fi\n\n    echo\n    echo \"=== Building ===\"\n    if [ -f \"package.json\" ] && grep -q \"build\" package.json; then\n        npm run build\n    elif [ -f \"setup.py\" ]; then\n        python setup.py build\n    fi\n\n    echo\n    echo \"=== Build Successful ===\"\n\n} 2>&1 | tee \"$BUILD_LOG\"\n\nexit_code=${PIPESTATUS[0]}\n\nif [ $exit_code -eq 0 ]; then\n    echo \"\u2713 Build passed\"\nelse\n    echo \"\u2717 Build failed\"\nfi\n\nexit $exit_code\n",
    "#!/bin/bash\n# Kubernetes deployment script\n\nNAMESPACE=\"${1:-default}\"\nDEPLOYMENT=\"${2}\"\nIMAGE=\"${3}\"\n\nif [ -z \"$DEPLOYMENT\" ] || [ -z \"$IMAGE\" ]; then\n    echo \"Usage: $0 <namespace> <deployment> <image>\"\n    exit 1\nfi\n\necho \"Deploying to Kubernetes\"\necho \"=======================\"\necho \"Namespace: $NAMESPACE\"\necho \"Deployment: $DEPLOYMENT\"\necho \"Image: $IMAGE\"\necho\n\n# Check if deployment exists\nif ! kubectl get deployment \"$DEPLOYMENT\" -n \"$NAMESPACE\" &>/dev/null; then\n    echo \"Error: Deployment $DEPLOYMENT not found in namespace $NAMESPACE\"\n    exit 1\nfi\n\n# Update deployment\necho \"Updating deployment...\"\nkubectl set image \"deployment/$DEPLOYMENT\"     \"$DEPLOYMENT=$IMAGE\"     -n \"$NAMESPACE\"\n\n# Wait for rollout\necho \"Waiting for rollout to complete...\"\nkubectl rollout status \"deployment/$DEPLOYMENT\" -n \"$NAMESPACE\"\n\n# Check status\nif [ $? -eq 0 ]; then\n    echo \"\u2713 Deployment successful\"\n\n    # Show new pods\n    echo\n    echo \"New pods:\"\n    kubectl get pods -n \"$NAMESPACE\" -l \"app=$DEPLOYMENT\"\nelse\n    echo \"\u2717 Deployment failed\"\n\n    # Rollback\n    echo \"Rolling back...\"\n    kubectl rollout undo \"deployment/$DEPLOYMENT\" -n \"$NAMESPACE\"\n\n    exit 1\nfi\n",
    "#!/bin/bash\n# Docker container health checker\n\ncheck_container() {\n    local container=$1\n\n    echo \"Checking: $container\"\n\n    # Check if container is running\n    if ! docker ps --format '{{.Names}}' | grep -q \"^$container$\"; then\n        echo \"  \u2717 Container is not running\"\n        return 1\n    fi\n\n    # Check health status\n    health=$(docker inspect --format='{{.State.Health.Status}}' \"$container\" 2>/dev/null)\n\n    if [ \"$health\" = \"healthy\" ]; then\n        echo \"  \u2713 Status: healthy\"\n        return 0\n    elif [ \"$health\" = \"unhealthy\" ]; then\n        echo \"  \u2717 Status: unhealthy\"\n\n        # Show recent health check logs\n        echo \"  Recent health checks:\"\n        docker inspect --format='{{range .State.Health.Log}}{{.Output}}{{end}}' \"$container\" | tail -5\n\n        return 1\n    else\n        # No health check defined\n        echo \"  \u26a0 No health check configured\"\n        return 0\n    fi\n}\n\nrestart_container() {\n    local container=$1\n\n    echo \"Restarting container: $container\"\n    docker restart \"$container\"\n\n    sleep 5\n\n    if check_container \"$container\"; then\n        echo \"  \u2713 Container restarted successfully\"\n        return 0\n    else\n        echo \"  \u2717 Container still unhealthy after restart\"\n        return 1\n    fi\n}\n\necho \"Docker Container Health Check\"\necho \"=============================\"\necho\n\nUNHEALTHY=()\n\n# Check all running containers\nfor container in $(docker ps --format '{{.Names}}'); do\n    if ! check_container \"$container\"; then\n        UNHEALTHY+=(\"$container\")\n    fi\n    echo\ndone\n\n# Try to restart unhealthy containers\nif [ ${#UNHEALTHY[@]} -gt 0 ]; then\n    echo \"Found ${#UNHEALTHY[@]} unhealthy container(s)\"\n    echo\n\n    for container in \"${UNHEALTHY[@]}\"; do\n        restart_container \"$container\"\n        echo\n    done\nfi\n",
    "#!/bin/bash\n# Sync environment variables between environments\n\nSOURCE_ENV=\"${1}\"\nTARGET_ENV=\"${2}\"\n\nif [ -z \"$SOURCE_ENV\" ] || [ -z \"$TARGET_ENV\" ]; then\n    echo \"Usage: $0 <source-env-file> <target-env-file>\"\n    exit 1\nfi\n\nif [ ! -f \"$SOURCE_ENV\" ]; then\n    echo \"Error: Source file not found: $SOURCE_ENV\"\n    exit 1\nfi\n\necho \"Environment Sync\"\necho \"================\"\necho \"Source: $SOURCE_ENV\"\necho \"Target: $TARGET_ENV\"\necho\n\n# Backup target if it exists\nif [ -f \"$TARGET_ENV\" ]; then\n    cp \"$TARGET_ENV\" \"${TARGET_ENV}.backup-$(date +%Y%m%d_%H%M%S)\"\n    echo \"\u2713 Backed up target file\"\nfi\n\n# Create target if it doesn't exist\ntouch \"$TARGET_ENV\"\n\n# Read source and update target\nwhile IFS='=' read -r key value; do\n    # Skip comments and empty lines\n    [[ \"$key\" =~ ^#.*$ ]] || [ -z \"$key\" ] && continue\n\n    # Remove existing key from target\n    sed -i \"/^$key=/d\" \"$TARGET_ENV\"\n\n    # Prompt for value\n    echo -n \"[$key] Current: $value, New value (Enter to keep): \"\n    read new_value\n\n    if [ -z \"$new_value\" ]; then\n        new_value=\"$value\"\n    fi\n\n    # Add to target\n    echo \"$key=$new_value\" >> \"$TARGET_ENV\"\n\ndone < \"$SOURCE_ENV\"\n\necho\necho \"\u2713 Environment sync complete\"\necho \"Updated: $TARGET_ENV\"\n",
    "#!/bin/bash\n# Rotate secrets and update services\n\nSECRETS_FILE=\"/etc/secrets/app.env\"\nSERVICES=(\"webapp\" \"api\" \"worker\")\n\nrotate_secret() {\n    local key=$1\n\n    # Generate new secret\n    local new_secret=$(openssl rand -base64 32)\n\n    echo \"Rotating: $key\"\n\n    # Update secrets file\n    sed -i \"s/^$key=.*/$key=$new_secret/\" \"$SECRETS_FILE\"\n\n    echo \"  \u2713 Updated secrets file\"\n\n    return 0\n}\n\nreload_services() {\n    echo\n    echo \"Reloading services...\"\n\n    for service in \"${SERVICES[@]}\"; do\n        echo \"  Restarting $service...\"\n        systemctl restart \"$service\"\n\n        if systemctl is-active --quiet \"$service\"; then\n            echo \"    \u2713 $service restarted successfully\"\n        else\n            echo \"    \u2717 $service failed to restart\"\n            return 1\n        fi\n    done\n\n    return 0\n}\n\necho \"Secret Rotation\"\necho \"===============\"\necho\n\n# Backup current secrets\ncp \"$SECRETS_FILE\" \"$SECRETS_FILE.backup-$(date +%Y%m%d_%H%M%S)\"\necho \"\u2713 Backed up secrets\"\necho\n\n# Rotate secrets\nrotate_secret \"API_KEY\"\nrotate_secret \"DB_PASSWORD\"\nrotate_secret \"JWT_SECRET\"\nrotate_secret \"ENCRYPTION_KEY\"\n\n# Reload services with new secrets\nif reload_services; then\n    echo\n    echo \"\u2713 Secret rotation complete\"\nelse\n    echo\n    echo \"\u2717 Failed to reload services\"\n    echo \"Restoring backup...\"\n    cp \"$SECRETS_FILE.backup-\"* \"$SECRETS_FILE\"\n    exit 1\nfi\n",
    "#!/bin/bash\n# Check backend servers behind load balancer\n\nBACKENDS=(\"10.0.1.10:8080\" \"10.0.1.11:8080\" \"10.0.1.12:8080\")\nHEALTH_ENDPOINT=\"/health\"\nTIMEOUT=5\n\ncheck_backend() {\n    local backend=$1\n    local url=\"http://$backend$HEALTH_ENDPOINT\"\n\n    echo -n \"Checking $backend... \"\n\n    response=$(curl -s -o /dev/null -w \"%{http_code}\" --max-time $TIMEOUT \"$url\" 2>/dev/null)\n\n    if [ \"$response\" = \"200\" ]; then\n        echo \"\u2713 UP (HTTP $response)\"\n        return 0\n    else\n        echo \"\u2717 DOWN (HTTP $response)\"\n        return 1\n    fi\n}\n\ndrain_backend() {\n    local backend=$1\n    local host=$(echo \"$backend\" | cut -d: -f1)\n\n    echo \"Draining backend: $backend\"\n\n    # This would integrate with your load balancer\n    # Example for nginx:\n    # echo \"server $host:8080 down;\" | nginx -s reload\n\n    echo \"  \u2713 Backend drained\"\n}\n\necho \"Load Balancer Health Check\"\necho \"==========================\"\necho\n\nUNHEALTHY=()\n\nfor backend in \"${BACKENDS[@]}\"; do\n    if ! check_backend \"$backend\"; then\n        UNHEALTHY+=(\"$backend\")\n    fi\ndone\n\necho\nif [ ${#UNHEALTHY[@]} -gt 0 ]; then\n    echo \"\u26a0 Unhealthy backends: ${#UNHEALTHY[@]}\"\n\n    for backend in \"${UNHEALTHY[@]}\"; do\n        echo \"  - $backend\"\n    done\n\n    # Optionally drain unhealthy backends\n    read -p \"Drain unhealthy backends? (y/n) \" -n 1 -r\n    echo\n\n    if [[ $REPLY =~ ^[Yy]$ ]]; then\n        for backend in \"${UNHEALTHY[@]}\"; do\n            drain_backend \"$backend\"\n        done\n    fi\n\n    exit 1\nelse\n    echo \"\u2713 All backends healthy\"\n    exit 0\nfi\n",
    "#!/bin/bash\n# Publish build artifacts to repository\n\nARTIFACT_FILE=\"${1}\"\nREPO_URL=\"${2:-https://artifacts.example.com}\"\nVERSION=\"${3:-$(git describe --tags --always)}\"\n\nif [ -z \"$ARTIFACT_FILE\" ] || [ ! -f \"$ARTIFACT_FILE\" ]; then\n    echo \"Usage: $0 <artifact-file> [repo-url] [version]\"\n    exit 1\nfi\n\necho \"Publishing Artifact\"\necho \"===================\"\necho \"File: $ARTIFACT_FILE\"\necho \"Version: $VERSION\"\necho \"Repository: $REPO_URL\"\necho\n\n# Calculate checksum\necho \"Calculating checksums...\"\nSHA256=$(sha256sum \"$ARTIFACT_FILE\" | awk '{print $1}')\nMD5=$(md5sum \"$ARTIFACT_FILE\" | awk '{print $1}')\n\necho \"  SHA256: $SHA256\"\necho \"  MD5: $MD5\"\n\n# Create metadata\nMETADATA_FILE=\"${ARTIFACT_FILE}.metadata.json\"\ncat > \"$METADATA_FILE\" <<EOF\n{\n  \"filename\": \"$(basename \"$ARTIFACT_FILE\")\",\n  \"version\": \"$VERSION\",\n  \"size\": $(stat -f%z \"$ARTIFACT_FILE\" 2>/dev/null || stat -c%s \"$ARTIFACT_FILE\"),\n  \"sha256\": \"$SHA256\",\n  \"md5\": \"$MD5\",\n  \"build_date\": \"$(date -Iseconds)\",\n  \"git_commit\": \"$(git rev-parse HEAD 2>/dev/null || echo 'unknown')\"\n}\nEOF\n\necho\necho \"\u2713 Metadata created: $METADATA_FILE\"\n\n# Upload artifact\necho\necho \"Uploading to repository...\"\n\ncurl -f -X POST     -H \"Content-Type: application/octet-stream\"     -H \"X-Artifact-Version: $VERSION\"     --data-binary \"@$ARTIFACT_FILE\"     \"$REPO_URL/upload\"\n\nif [ $? -eq 0 ]; then\n    echo \"\u2713 Artifact published successfully\"\n\n    # Upload metadata\n    curl -f -X POST         -H \"Content-Type: application/json\"         --data-binary \"@$METADATA_FILE\"         \"$REPO_URL/metadata\"\n\n    echo \"\u2713 Metadata published\"\nelse\n    echo \"\u2717 Failed to publish artifact\"\n    exit 1\nfi\n",
    "#!/bin/bash\n# Check CI/CD pipeline status\n\nPIPELINE_ID=\"${1}\"\nAPI_URL=\"${CI_API_URL:-https://ci.example.com/api}\"\nAPI_TOKEN=\"${CI_API_TOKEN}\"\n\nif [ -z \"$PIPELINE_ID\" ]; then\n    echo \"Usage: $0 <pipeline-id>\"\n    exit 1\nfi\n\nget_pipeline_status() {\n    curl -s -H \"Authorization: Bearer $API_TOKEN\"         \"$API_URL/pipelines/$PIPELINE_ID\"\n}\n\nwait_for_completion() {\n    echo \"Waiting for pipeline $PIPELINE_ID to complete...\"\n\n    while true; do\n        response=$(get_pipeline_status)\n        status=$(echo \"$response\" | jq -r '.status')\n\n        echo -n \".\"\n\n        case $status in\n            success)\n                echo\n                echo \"\u2713 Pipeline succeeded\"\n                return 0\n                ;;\n            failed)\n                echo\n                echo \"\u2717 Pipeline failed\"\n                echo \"$response\" | jq -r '.stages[] | select(.status==\"failed\") | \"  Failed stage: \\(.name)\"'\n                return 1\n                ;;\n            running|pending)\n                sleep 10\n                ;;\n            *)\n                echo\n                echo \"Unknown status: $status\"\n                return 1\n                ;;\n        esac\n    done\n}\n\necho \"Pipeline Status Check\"\necho \"====================\"\necho \"Pipeline ID: $PIPELINE_ID\"\necho\n\nwait_for_completion\nexit $?\n",
    "#!/bin/bash\n# Container registry cleanup\n\nREGISTRY=\"registry.example.com\"\nKEEP_TAGS=10\n\necho \"Cleaning registry: $REGISTRY\"\n\n# Implementation details...\necho \"\u2713 Cleanup complete\"\n",
    "#!/bin/bash\n# Service mesh configuration\n\nSERVICE=\"${1}\"\nMESH_CONFIG=\"/etc/istio/configs/${SERVICE}.yaml\"\n\necho \"Configuring service mesh for: $SERVICE\"\n\n# Generate mesh config\ncat > \"$MESH_CONFIG\" <<EOF\napiVersion: networking.istio.io/v1\nkind: VirtualService\nmetadata:\n  name: $SERVICE\nspec:\n  hosts:\n  - $SERVICE\n  http:\n  - route:\n    - destination:\n        host: $SERVICE\nEOF\n\necho \"\u2713 Mesh configured\"\n",
    "#!/bin/bash\n# Auto-scaling trigger\n\nMETRIC=\"${1:-cpu}\"\nTHRESHOLD=\"${2:-80}\"\n\necho \"Monitoring $METRIC for auto-scaling (threshold: $THRESHOLD%)\"\n\n# Monitor and scale\ncurrent_value=$(get_metric_value \"$METRIC\")\n\nif [ \"$current_value\" -gt \"$THRESHOLD\" ]; then\n    echo \"Scaling up...\"\n    kubectl scale deployment/app --replicas=$((current_replicas + 1))\nfi\n",
    "#!/bin/bash\n# Configuration drift detector\n\nEXPECTED_CONFIG=\"/etc/app/config.expected.json\"\nACTUAL_CONFIG=\"/etc/app/config.json\"\n\necho \"Checking configuration drift...\"\n\ndiff -u \"$EXPECTED_CONFIG\" \"$ACTUAL_CONFIG\" || {\n    echo \"\u26a0 Configuration drift detected\"\n    exit 1\n}\n\necho \"\u2713 No drift\"\n",
    "#!/bin/bash\n# Feature flag manager\n\nFLAG_NAME=\"${1}\"\nFLAG_VALUE=\"${2}\"\nFLAGS_FILE=\"/etc/app/feature-flags.json\"\n\necho \"Setting feature flag: $FLAG_NAME=$FLAG_VALUE\"\n\n# Update flag\njq \".$FLAG_NAME = $FLAG_VALUE\" \"$FLAGS_FILE\" > \"$FLAGS_FILE.tmp\"\nmv \"$FLAGS_FILE.tmp\" \"$FLAGS_FILE\"\n\n# Reload app\nsystemctl reload app\n\necho \"\u2713 Feature flag updated\"\n",
    "#!/bin/bash\n# Canary deployment validator\n\nCANARY_ENDPOINT=\"http://canary.example.com\"\nPRODUCTION_ENDPOINT=\"http://prod.example.com\"\nERROR_THRESHOLD=1\n\necho \"Validating canary deployment...\"\n\ncanary_errors=$(curl -s \"$CANARY_ENDPOINT/metrics\" | jq '.error_rate')\nprod_errors=$(curl -s \"$PRODUCTION_ENDPOINT/metrics\" | jq '.error_rate')\n\nif (( $(echo \"$canary_errors > $prod_errors + $ERROR_THRESHOLD\" | bc -l) )); then\n    echo \"\u2717 Canary validation failed\"\n    echo \"Rolling back...\"\n    exit 1\nfi\n\necho \"\u2713 Canary validated\"\n",
    "#!/bin/bash\n# Dependency version checker\n\nPROJECT_FILE=\"${1:-package.json}\"\n\necho \"Checking dependencies for updates...\"\n\nif [ -f \"package.json\" ]; then\n    npm outdated\nelif [ -f \"requirements.txt\" ]; then\n    pip list --outdated\nelif [ -f \"Gemfile\" ]; then\n    bundle outdated\nfi\n",
    "#!/bin/bash\n# Service dependency graph generator\n\nOUTPUT_FILE=\"dependencies.dot\"\n\necho \"Generating service dependency graph...\"\n\necho \"digraph services {\" > \"$OUTPUT_FILE\"\n\n# Scan services and their dependencies\nfor service in $(kubectl get svc -o name); do\n    dependencies=$(kubectl get svc \"$service\" -o json | jq -r '.metadata.annotations.dependencies')\n    echo \"  $service -> $dependencies\" >> \"$OUTPUT_FILE\"\ndone\n\necho \"}\" >> \"$OUTPUT_FILE\"\n\ndot -Tpng \"$OUTPUT_FILE\" -o dependencies.png\n\necho \"\u2713 Graph generated: dependencies.png\"\n",
    "#!/bin/bash\n# Rollback automation\n\nDEPLOYMENT=\"${1}\"\nNAMESPACE=\"${2:-default}\"\n\necho \"Rolling back deployment: $DEPLOYMENT\"\n\nkubectl rollout undo \"deployment/$DEPLOYMENT\" -n \"$NAMESPACE\"\nkubectl rollout status \"deployment/$DEPLOYMENT\" -n \"$NAMESPACE\"\n\nif [ $? -eq 0 ]; then\n    echo \"\u2713 Rollback successful\"\nelse\n    echo \"\u2717 Rollback failed\"\n    exit 1\nfi\n",
    "#!/bin/bash\n# Infrastructure drift checker\n\nTERRAFORM_DIR=\"${1:-.}\"\n\ncd \"$TERRAFORM_DIR\"\n\necho \"Checking infrastructure drift...\"\n\nterraform plan -detailed-exitcode\n\ncase $? in\n    0)\n        echo \"\u2713 No drift detected\"\n        ;;\n    2)\n        echo \"\u26a0 Drift detected\"\n        terraform plan\n        ;;\n    *)\n        echo \"\u2717 Error running terraform\"\n        exit 1\n        ;;\nesac\n",
    "#!/bin/bash\n# MySQL database backup with compression\n\nDB_USER=\"backup_user\"\nDB_PASS=\"$(cat /etc/mysql/backup.pass)\"\nBACKUP_DIR=\"/backup/mysql\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Get all databases\nDATABASES=$(mysql -u \"$DB_USER\" -p\"$DB_PASS\" -e \"SHOW DATABASES;\" | grep -Ev \"(Database|information_schema|performance_schema|mysql)\")\n\nfor db in $DATABASES; do\n    echo \"Backing up database: $db\"\n\n    mysqldump -u \"$DB_USER\" -p\"$DB_PASS\"         --single-transaction         --routines         --triggers         \"$db\" | gzip > \"$BACKUP_DIR/${db}_${DATE}.sql.gz\"\n\n    if [ $? -eq 0 ]; then\n        echo \"\u2713 $db backed up successfully\"\n    else\n        echo \"\u2717 Failed to backup $db\"\n    fi\ndone\n\n# Remove backups older than 7 days\nfind \"$BACKUP_DIR\" -name \"*.sql.gz\" -mtime +7 -delete\n\necho \"Database backup complete\"\n",
    "#!/bin/bash\n# PostgreSQL backup script\n\nPGUSER=\"postgres\"\nBACKUP_DIR=\"/backup/postgresql\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\nmkdir -p \"$BACKUP_DIR\"\n\n# Backup all databases\necho \"Backing up all PostgreSQL databases...\"\n\npg_dumpall -U \"$PGUSER\" | gzip > \"$BACKUP_DIR/all-databases_${DATE}.sql.gz\"\n\n# Backup individual databases\nfor db in $(psql -U \"$PGUSER\" -t -c \"SELECT datname FROM pg_database WHERE datname NOT IN ('template0', 'template1', 'postgres')\"); do\n    db=$(echo \"$db\" | tr -d ' ')\n    echo \"Backing up: $db\"\n\n    pg_dump -U \"$PGUSER\" -Fc \"$db\" > \"$BACKUP_DIR/${db}_${DATE}.dump\"\ndone\n\n# Backup globals (users, roles, tablespaces)\npg_dumpall -U \"$PGUSER\" --globals-only > \"$BACKUP_DIR/globals_${DATE}.sql\"\n\n# Clean old backups\nfind \"$BACKUP_DIR\" -name \"*.sql.gz\" -mtime +14 -delete\nfind \"$BACKUP_DIR\" -name \"*.dump\" -mtime +14 -delete\n\necho \"\u2713 PostgreSQL backup complete\"\n",
    "#!/bin/bash\n# Database restore script\n\nBACKUP_FILE=\"${1}\"\nDB_NAME=\"${2}\"\nDB_TYPE=\"${3:-mysql}\"\n\nif [ -z \"$BACKUP_FILE\" ] || [ -z \"$DB_NAME\" ]; then\n    echo \"Usage: $0 <backup-file> <database-name> [mysql|postgresql]\"\n    exit 1\nfi\n\nif [ ! -f \"$BACKUP_FILE\" ]; then\n    echo \"Error: Backup file not found: $BACKUP_FILE\"\n    exit 1\nfi\n\necho \"Database Restore\"\necho \"================\"\necho \"File: $BACKUP_FILE\"\necho \"Database: $DB_NAME\"\necho \"Type: $DB_TYPE\"\necho\n\nread -p \"This will overwrite database $DB_NAME. Continue? (yes/no) \" -r\nif [ \"$REPLY\" != \"yes\" ]; then\n    echo \"Restore cancelled\"\n    exit 0\nfi\n\nrestore_mysql() {\n    echo \"Restoring MySQL database...\"\n\n    # Create database if it doesn't exist\n    mysql -e \"CREATE DATABASE IF NOT EXISTS $DB_NAME\"\n\n    # Restore\n    if [[ \"$BACKUP_FILE\" == *.gz ]]; then\n        gunzip < \"$BACKUP_FILE\" | mysql \"$DB_NAME\"\n    else\n        mysql \"$DB_NAME\" < \"$BACKUP_FILE\"\n    fi\n}\n\nrestore_postgresql() {\n    echo \"Restoring PostgreSQL database...\"\n\n    # Drop and recreate database\n    dropdb \"$DB_NAME\" 2>/dev/null\n    createdb \"$DB_NAME\"\n\n    # Restore\n    if [[ \"$BACKUP_FILE\" == *.dump ]]; then\n        pg_restore -d \"$DB_NAME\" \"$BACKUP_FILE\"\n    else\n        psql \"$DB_NAME\" < \"$BACKUP_FILE\"\n    fi\n}\n\ncase $DB_TYPE in\n    mysql)\n        restore_mysql\n        ;;\n    postgresql|postgres)\n        restore_postgresql\n        ;;\n    *)\n        echo \"Error: Unknown database type: $DB_TYPE\"\n        exit 1\n        ;;\nesac\n\nif [ $? -eq 0 ]; then\n    echo \"\u2713 Database restored successfully\"\nelse\n    echo \"\u2717 Restore failed\"\n    exit 1\nfi\n",
    "#!/bin/bash\n# Analyze slow queries\n\nDB_USER=\"root\"\nDB_PASS=\"$(cat /etc/mysql/root.pass)\"\nSLOW_QUERY_LOG=\"/var/log/mysql/slow-query.log\"\nREPORT_FILE=\"/tmp/slow-queries-$(date +%Y%m%d).txt\"\n\n{\n    echo \"Slow Query Analysis\"\n    echo \"===================\"\n    echo \"Date: $(date)\"\n    echo\n\n    if [ ! -f \"$SLOW_QUERY_LOG\" ]; then\n        echo \"Error: Slow query log not found\"\n        exit 1\n    fi\n\n    echo \"=== Top 10 Slowest Queries ===\"\n    mysqldumpslow -s t -t 10 \"$SLOW_QUERY_LOG\"\n\n    echo\n    echo \"=== Most Frequent Slow Queries ===\"\n    mysqldumpslow -s c -t 10 \"$SLOW_QUERY_LOG\"\n\n    echo\n    echo \"=== Table Statistics ===\"\n    mysql -u \"$DB_USER\" -p\"$DB_PASS\" -e \"\n        SELECT\n            table_schema AS 'Database',\n            table_name AS 'Table',\n            ROUND(((data_length + index_length) / 1024 / 1024), 2) AS 'Size (MB)',\n            table_rows AS 'Rows'\n        FROM information_schema.TABLES\n        WHERE table_schema NOT IN ('information_schema', 'mysql', 'performance_schema')\n        ORDER BY (data_length + index_length) DESC\n        LIMIT 10;\n    \"\n\n    echo\n    echo \"=== Current Running Queries ===\"\n    mysql -u \"$DB_USER\" -p\"$DB_PASS\" -e \"SHOW FULL PROCESSLIST\"\n\n} | tee \"$REPORT_FILE\"\n\necho\necho \"Report saved to: $REPORT_FILE\"\n",
    "#!/bin/bash\n# Monitor database connections\n\nDB_USER=\"monitor\"\nDB_PASS=\"$(cat /etc/mysql/monitor.pass)\"\nMAX_CONNECTIONS=150\nWARNING_THRESHOLD=120\n\nget_connection_count() {\n    mysql -u \"$DB_USER\" -p\"$DB_PASS\" -sN -e \"SHOW STATUS LIKE 'Threads_connected'\" | awk '{print $2}'\n}\n\nget_max_used_connections() {\n    mysql -u \"$DB_USER\" -p\"$DB_PASS\" -sN -e \"SHOW STATUS LIKE 'Max_used_connections'\" | awk '{print $2}'\n}\n\necho \"Database Connection Monitor\"\necho \"===========================\"\n\nCURRENT=$(get_connection_count)\nMAX_USED=$(get_max_used_connections)\nPERCENT=$((CURRENT * 100 / MAX_CONNECTIONS))\n\necho \"Current connections: $CURRENT\"\necho \"Max connections: $MAX_CONNECTIONS\"\necho \"Max used: $MAX_USED\"\necho \"Usage: ${PERCENT}%\"\necho\n\n# Show connection details\necho \"Connections by user:\"\nmysql -u \"$DB_USER\" -p\"$DB_PASS\" -e \"\n    SELECT user, COUNT(*) as connections\n    FROM information_schema.PROCESSLIST\n    GROUP BY user\n    ORDER BY connections DESC;\n\"\n\necho\necho \"Connections by host:\"\nmysql -u \"$DB_USER\" -p\"$DB_PASS\" -e \"\n    SELECT host, COUNT(*) as connections\n    FROM information_schema.PROCESSLIST\n    GROUP BY host\n    ORDER BY connections DESC;\n\"\n\n# Alert if threshold exceeded\nif [ \"$CURRENT\" -gt \"$WARNING_THRESHOLD\" ]; then\n    echo\n    echo \"\u26a0 WARNING: Connection count exceeds threshold\"\n    echo \"Current: $CURRENT, Threshold: $WARNING_THRESHOLD\"\n    exit 1\nelse\n    echo\n    echo \"\u2713 Connection count normal\"\n    exit 0\nfi\n",
    "#!/bin/bash\n# Database replication checker\n\nMASTER_HOST=\"db-master\"\nSLAVE_HOST=\"db-slave\"\n\necho \"Checking replication status...\"\n\n# Check slave status\nmysql -h \"$SLAVE_HOST\" -e \"SHOW SLAVE STATUS\\G\" | grep -E \"(Slave_IO_Running|Slave_SQL_Running|Seconds_Behind_Master)\"\n\necho \"\u2713 Replication check complete\"\n",
    "#!/bin/bash\n# Index optimization\n\nDB_NAME=\"${1}\"\n\necho \"Analyzing indexes for: $DB_NAME\"\n\nmysql \"$DB_NAME\" -e \"\n    SELECT\n        table_schema,\n        table_name,\n        index_name,\n        SEQ_IN_INDEX,\n        column_name,\n        cardinality\n    FROM information_schema.STATISTICS\n    WHERE table_schema = '$DB_NAME'\n    AND cardinality IS NOT NULL\n    ORDER BY table_name, index_name, SEQ_IN_INDEX;\n\"\n",
    "#!/bin/bash\n# Database user audit\n\necho \"Database User Audit\"\necho \"===================\"\n\nmysql -e \"\n    SELECT\n        user,\n        host,\n        password_expired,\n        password_last_changed,\n        password_lifetime\n    FROM mysql.user\n    ORDER BY user, host;\n\"\n",
    "#!/bin/bash\n# Table size analyzer\n\nDB_NAME=\"${1}\"\n\nmysql \"$DB_NAME\" -e \"\n    SELECT\n        table_name,\n        ROUND(((data_length + index_length) / 1024 / 1024), 2) AS 'Size (MB)',\n        ROUND((data_length / 1024 / 1024), 2) AS 'Data (MB)',\n        ROUND((index_length / 1024 / 1024), 2) AS 'Index (MB)',\n        table_rows,\n        ROUND((data_length / table_rows), 2) AS 'Avg Row Length'\n    FROM information_schema.TABLES\n    WHERE table_schema = '$DB_NAME'\n    ORDER BY (data_length + index_length) DESC;\n\"\n",
    "#!/bin/bash\n# Database vacuum (PostgreSQL)\n\nDB_NAME=\"${1:-postgres}\"\n\necho \"Running VACUUM ANALYZE on: $DB_NAME\"\n\npsql -d \"$DB_NAME\" -c \"VACUUM ANALYZE VERBOSE;\"\n\necho \"\u2713 Vacuum complete\"\n",
    "#!/bin/bash\n# Transaction log monitor\n\necho \"Monitoring transaction logs...\"\n\nmysql -e \"SHOW ENGINE INNODB STATUS\\G\" | grep -A 20 \"TRANSACTIONS\"\n",
    "#!/bin/bash\n# Database migration runner\n\nMIGRATION_DIR=\"${1:-migrations}\"\n\necho \"Running database migrations from: $MIGRATION_DIR\"\n\nfor file in \"$MIGRATION_DIR\"/*.sql; do\n    echo \"Applying: $(basename \"$file\")\"\n    mysql < \"$file\"\ndone\n\necho \"\u2713 Migrations complete\"\n",
    "#!/bin/bash\n# Query cache stats\n\nmysql -e \"SHOW STATUS LIKE 'Qcache%';\"\n",
    "#!/bin/bash\n# Database deadlock detector\n\nmysql -e \"SHOW ENGINE INNODB STATUS\\G\" | grep -A 50 \"LATEST DETECTED DEADLOCK\"\n",
    "#!/bin/bash\n# Schema diff checker\n\nDB1=\"${1}\"\nDB2=\"${2}\"\n\necho \"Comparing schemas: $DB1 vs $DB2\"\n\ndiff <(mysqldump --no-data \"$DB1\") <(mysqldump --no-data \"$DB2\")\n",
    "#!/bin/bash\n# Simple port scanner\n\nHOST=\"${1:-localhost}\"\nSTART_PORT=\"${2:-1}\"\nEND_PORT=\"${3:-1024}\"\n\necho \"Scanning $HOST ports $START_PORT-$END_PORT\"\necho \"==========================================\"\n\nfor port in $(seq $START_PORT $END_PORT); do\n    timeout 1 bash -c \"echo >/dev/tcp/$HOST/$port\" 2>/dev/null && {\n        echo \"Port $port: OPEN\"\n\n        # Try to identify service\n        SERVICE=$(getent services $port | awk '{print $1}')\n        if [ -n \"$SERVICE\" ]; then\n            echo \"  Service: $SERVICE\"\n        fi\n    }\ndone\n\necho\necho \"Scan complete\"\n",
    "#!/bin/bash\n# Monitor network bandwidth usage\n\nINTERFACE=\"${1:-eth0}\"\nINTERVAL=\"${2:-1}\"\n\necho \"Monitoring bandwidth on $INTERFACE (${INTERVAL}s intervals)\"\necho \"Press Ctrl+C to stop\"\necho\n\nget_bytes() {\n    cat \"/sys/class/net/$INTERFACE/statistics/$1_bytes\"\n}\n\nformat_bps() {\n    local bps=$1\n    if [ $bps -gt 1073741824 ]; then\n        echo \"$(awk \"BEGIN {printf \"%.2f\", $bps/1073741824}\") Gbps\"\n    elif [ $bps -gt 1048576 ]; then\n        echo \"$(awk \"BEGIN {printf \"%.2f\", $bps/1048576}\") Mbps\"\n    elif [ $bps -gt 1024 ]; then\n        echo \"$(awk \"BEGIN {printf \"%.2f\", $bps/1024}\") Kbps\"\n    else\n        echo \"$bps bps\"\n    fi\n}\n\nrx_old=$(get_bytes rx)\ntx_old=$(get_bytes tx)\n\nwhile true; do\n    sleep \"$INTERVAL\"\n\n    rx_new=$(get_bytes rx)\n    tx_new=$(get_bytes tx)\n\n    rx_bps=$(( (rx_new - rx_old) * 8 / INTERVAL ))\n    tx_bps=$(( (tx_new - tx_old) * 8 / INTERVAL ))\n\n    echo \"$(date '+%H:%M:%S') | RX: $(format_bps $rx_bps) | TX: $(format_bps $tx_bps)\"\n\n    rx_old=$rx_new\n    tx_old=$tx_new\ndone\n",
    "#!/bin/bash\n# Manage firewall rules\n\nACTION=\"${1}\"\nPORT=\"${2}\"\nPROTOCOL=\"${3:-tcp}\"\n\nusage() {\n    echo \"Usage: $0 <allow|deny|list> [port] [protocol]\"\n    exit 1\n}\n\nlist_rules() {\n    echo \"Current Firewall Rules\"\n    echo \"======================\"\n\n    if command -v ufw &>/dev/null; then\n        ufw status numbered\n    elif command -v firewall-cmd &>/dev/null; then\n        firewall-cmd --list-all\n    elif command -v iptables &>/dev/null; then\n        iptables -L -n -v\n    else\n        echo \"No firewall found\"\n        exit 1\n    fi\n}\n\nallow_port() {\n    local port=$1\n    local proto=$2\n\n    echo \"Allowing $proto port $port...\"\n\n    if command -v ufw &>/dev/null; then\n        ufw allow \"$port/$proto\"\n    elif command -v firewall-cmd &>/dev/null; then\n        firewall-cmd --permanent --add-port=\"$port/$proto\"\n        firewall-cmd --reload\n    elif command -v iptables &>/dev/null; then\n        iptables -A INPUT -p \"$proto\" --dport \"$port\" -j ACCEPT\n    fi\n\n    echo \"\u2713 Port $port/$proto allowed\"\n}\n\ndeny_port() {\n    local port=$1\n    local proto=$2\n\n    echo \"Denying $proto port $port...\"\n\n    if command -v ufw &>/dev/null; then\n        ufw deny \"$port/$proto\"\n    elif command -v firewall-cmd &>/dev/null; then\n        firewall-cmd --permanent --remove-port=\"$port/$proto\"\n        firewall-cmd --reload\n    elif command -v iptables &>/dev/null; then\n        iptables -A INPUT -p \"$proto\" --dport \"$port\" -j DROP\n    fi\n\n    echo \"\u2713 Port $port/$proto denied\"\n}\n\ncase $ACTION in\n    allow)\n        [ -z \"$PORT\" ] && usage\n        allow_port \"$PORT\" \"$PROTOCOL\"\n        ;;\n    deny)\n        [ -z \"$PORT\" ] && usage\n        deny_port \"$PORT\" \"$PROTOCOL\"\n        ;;\n    list)\n        list_rules\n        ;;\n    *)\n        usage\n        ;;\nesac\n",
    "#!/bin/bash\n# Advanced DNS lookup tool\n\nDOMAIN=\"${1}\"\n\nif [ -z \"$DOMAIN\" ]; then\n    echo \"Usage: $0 <domain>\"\n    exit 1\nfi\n\necho \"DNS Lookup: $DOMAIN\"\necho \"===================\"\necho\n\necho \"=== A Records ===\"\ndig +short A \"$DOMAIN\"\n\necho\necho \"=== AAAA Records (IPv6) ===\"\ndig +short AAAA \"$DOMAIN\"\n\necho\necho \"=== MX Records ===\"\ndig +short MX \"$DOMAIN\"\n\necho\necho \"=== NS Records ===\"\ndig +short NS \"$DOMAIN\"\n\necho\necho \"=== TXT Records ===\"\ndig +short TXT \"$DOMAIN\"\n\necho\necho \"=== SOA Record ===\"\ndig +short SOA \"$DOMAIN\"\n\necho\necho \"=== Reverse DNS ===\"\nIP=$(dig +short A \"$DOMAIN\" | head -1)\nif [ -n \"$IP\" ]; then\n    dig +short -x \"$IP\"\nfi\n",
    "#!/bin/bash\n# Test network connectivity to multiple hosts\n\nHOSTS=(\"8.8.8.8\" \"1.1.1.1\" \"google.com\" \"github.com\")\nTIMEOUT=5\n\necho \"Network Connectivity Test\"\necho \"=========================\"\necho\n\ntest_ping() {\n    local host=$1\n\n    echo -n \"Testing $host (ping)... \"\n\n    if ping -c 1 -W $TIMEOUT \"$host\" &>/dev/null; then\n        echo \"\u2713 OK\"\n        return 0\n    else\n        echo \"\u2717 FAILED\"\n        return 1\n    fi\n}\n\ntest_dns() {\n    local host=$1\n\n    echo -n \"Testing $host (DNS)... \"\n\n    if nslookup \"$host\" &>/dev/null; then\n        echo \"\u2713 OK\"\n        return 0\n    else\n        echo \"\u2717 FAILED\"\n        return 1\n    fi\n}\n\ntest_http() {\n    local host=$1\n\n    echo -n \"Testing $host (HTTP)... \"\n\n    if curl -s -o /dev/null -w \"%{http_code}\" --max-time $TIMEOUT \"http://$host\" | grep -q \"^[23]\"; then\n        echo \"\u2713 OK\"\n        return 0\n    else\n        echo \"\u2717 FAILED\"\n        return 1\n    fi\n}\n\nFAILURES=0\n\nfor host in \"${HOSTS[@]}\"; do\n    test_ping \"$host\" || ((FAILURES++))\n    test_dns \"$host\" || ((FAILURES++))\n    test_http \"$host\" || ((FAILURES++))\n    echo\ndone\n\necho \"===================\"\nif [ $FAILURES -eq 0 ]; then\n    echo \"\u2713 All tests passed\"\n    exit 0\nelse\n    echo \"\u2717 $FAILURES test(s) failed\"\n    exit 1\nfi\n",
    "#!/bin/bash\n# SSL certificate checker\n\nDOMAIN=\"${1}\"\nPORT=\"${2:-443}\"\n\necho | openssl s_client -servername \"$DOMAIN\" -connect \"$DOMAIN:$PORT\" 2>/dev/null |     openssl x509 -noout -dates -subject -issuer\n",
    "#!/bin/bash\n# Network latency monitor\n\nTARGET=\"${1:-8.8.8.8}\"\n\necho \"Monitoring latency to $TARGET...\"\n\nping \"$TARGET\" | while read line; do\n    echo \"$(date '+%Y-%m-%d %H:%M:%S') $line\"\ndone\n",
    "#!/bin/bash\n# TCP connection monitor\n\nPORT=\"${1:-80}\"\n\necho \"Monitoring TCP connections on port $PORT...\"\n\nwatch -n 1 \"ss -tan | grep :$PORT | wc -l\"\n",
    "#!/bin/bash\n# Network interface stats\n\nip -s link show\n",
    "#!/bin/bash\n# Route tracer\n\nHOST=\"${1}\"\n\ntraceroute -n \"$HOST\"\n",
    "#!/bin/bash\n# ARP table viewer\n\narp -a\n",
    "#!/bin/bash\n# Network packet capture\n\nINTERFACE=\"${1:-eth0}\"\nCOUNT=\"${2:-100}\"\n\ntcpdump -i \"$INTERFACE\" -c \"$COUNT\" -w \"capture-$(date +%Y%m%d_%H%M%S).pcap\"\n",
    "#!/bin/bash\n# VPN status checker\n\necho \"VPN Status\"\necho \"==========\"\n\nip link show | grep -i tun\n",
    "#!/bin/bash\n# Bandwidth limiter\n\nINTERFACE=\"${1}\"\nLIMIT=\"${2:-1mbit}\"\n\ntc qdisc add dev \"$INTERFACE\" root tbf rate \"$LIMIT\" burst 32kbit latency 400ms\n\necho \"\u2713 Bandwidth limited to $LIMIT on $INTERFACE\"\n",
    "#!/bin/bash\n# Network scan for live hosts\n\nNETWORK=\"${1:-192.168.1.0/24}\"\n\necho \"Scanning network: $NETWORK\"\n\nnmap -sn \"$NETWORK\" | grep \"Nmap scan report\"\n",
    "#!/bin/bash\n# System resource monitoring with alerts\n\nCPU_THRESHOLD=80\nMEM_THRESHOLD=90\nDISK_THRESHOLD=85\n\ncheck_cpu() {\n    CPU_USAGE=$(top -bn1 | grep \"Cpu(s)\" | awk '{print $2}' | cut -d'%' -f1 | cut -d'.' -f1)\n\n    if [ \"$CPU_USAGE\" -gt \"$CPU_THRESHOLD\" ]; then\n        echo \"ALERT: High CPU usage: ${CPU_USAGE}%\"\n        top -bn1 | head -20\n        return 1\n    fi\n\n    echo \"CPU: ${CPU_USAGE}% (OK)\"\n    return 0\n}\n\ncheck_memory() {\n    MEM_USAGE=$(free | grep Mem | awk '{printf(\"%.0f\", ($3/$2) * 100)}')\n\n    if [ \"$MEM_USAGE\" -gt \"$MEM_THRESHOLD\" ]; then\n        echo \"ALERT: High memory usage: ${MEM_USAGE}%\"\n        ps aux --sort=-%mem | head -10\n        return 1\n    fi\n\n    echo \"Memory: ${MEM_USAGE}% (OK)\"\n    return 0\n}\n\ncheck_disk() {\n    DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | cut -d'%' -f1)\n\n    if [ \"$DISK_USAGE\" -gt \"$DISK_THRESHOLD\" ]; then\n        echo \"ALERT: High disk usage: ${DISK_USAGE}%\"\n        du -sh /* 2>/dev/null | sort -hr | head -10\n        return 1\n    fi\n\n    echo \"Disk: ${DISK_USAGE}% (OK)\"\n    return 0\n}\n\necho \"=== System Resource Check ===\"\necho \"Thresholds: CPU:$CPU_THRESHOLD% MEM:$MEM_THRESHOLD% DISK:$DISK_THRESHOLD%\"\necho\n\nALERTS=0\n\ncheck_cpu || ((ALERTS++))\ncheck_memory || ((ALERTS++))\ncheck_disk || ((ALERTS++))\n\necho\nif [ $ALERTS -gt 0 ]; then\n    echo \"Status: $ALERTS alert(s) detected\"\n    exit 1\nelse\n    echo \"Status: All systems normal\"\n    exit 0\nfi\n",
    "#!/bin/bash\n# Aggregate logs from multiple sources\n\nOUTPUT_DIR=\"/var/log/aggregated\"\nDATE=$(date +%Y%m%d)\n\nmkdir -p \"$OUTPUT_DIR\"\n\naggregate_logs() {\n    echo \"Aggregating logs for $(date)\"\n\n    # System logs\n    {\n        echo \"=== System Logs ===\"\n        tail -n 1000 /var/log/syslog\n    } > \"$OUTPUT_DIR/system-$DATE.log\"\n\n    # Application logs\n    {\n        echo \"=== Application Logs ===\"\n        find /var/log/app -name \"*.log\" -exec tail -n 100 {} \\;\n    } > \"$OUTPUT_DIR/app-$DATE.log\"\n\n    # Web server logs\n    {\n        echo \"=== Web Server Logs ===\"\n        tail -n 1000 /var/log/nginx/access.log\n        tail -n 1000 /var/log/nginx/error.log\n    } > \"$OUTPUT_DIR/web-$DATE.log\"\n\n    # Database logs\n    {\n        echo \"=== Database Logs ===\"\n        tail -n 1000 /var/log/mysql/error.log\n    } > \"$OUTPUT_DIR/db-$DATE.log\"\n\n    echo \"\u2713 Logs aggregated to: $OUTPUT_DIR\"\n}\n\ncompress_old_logs() {\n    echo \"Compressing old logs...\"\n\n    find \"$OUTPUT_DIR\" -name \"*.log\" -mtime +1 ! -name \"*.gz\" -exec gzip {} \\;\n    find \"$OUTPUT_DIR\" -name \"*.gz\" -mtime +30 -delete\n\n    echo \"\u2713 Old logs compressed\"\n}\n\naggregate_logs\ncompress_old_logs\n",
    "#!/bin/bash\n# Analyze error logs for patterns\n\nLOG_FILE=\"${1:-/var/log/syslog}\"\nTOP_N=\"${2:-10}\"\n\nif [ ! -f \"$LOG_FILE\" ]; then\n    echo \"Error: Log file not found: $LOG_FILE\"\n    exit 1\nfi\n\necho \"Error Log Analysis: $LOG_FILE\"\necho \"==============================\"\necho\n\necho \"=== Top $TOP_N Error Messages ===\"\ngrep -i error \"$LOG_FILE\" |     sed 's/[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}/IP/g' |     sed 's/[0-9]\\{4\\}-[0-9]\\{2\\}-[0-9]\\{2\\}/DATE/g' |     sort | uniq -c | sort -rn | head -n \"$TOP_N\"\n\necho\necho \"=== Error Frequency by Hour ===\"\ngrep -i error \"$LOG_FILE\" |     awk '{print $3}' | cut -d: -f1 | sort | uniq -c\n\necho\necho \"=== Recent Errors (Last 20) ===\"\ngrep -i error \"$LOG_FILE\" | tail -20\n",
    "#!/bin/bash\n# Collect system performance metrics\n\nMETRICS_FILE=\"/var/log/metrics/$(date +%Y%m%d_%H%M%S).json\"\n\nmkdir -p \"$(dirname \"$METRICS_FILE\")\"\n\n{\n    echo \"{\"\n    echo \"  \"timestamp\": \"$(date -Iseconds)\",\"\n    echo \"  \"hostname\": \"$(hostname)\",\"\n    echo \"  \"cpu\": {\"\n    echo \"    \"usage\": $(top -bn1 | grep \"Cpu(s)\" | awk '{print $2}' | cut -d'%' -f1),\"\n    echo \"    \"cores\": $(nproc),\"\n    echo \"    \"load_avg\": \"$(uptime | awk -F'load average:' '{print $2}' | xargs)\"\"\n    echo \"  },\"\n    echo \"  \"memory\": {\"\n    echo \"    \"total_mb\": $(free -m | awk 'NR==2{print $2}'),\"\n    echo \"    \"used_mb\": $(free -m | awk 'NR==2{print $3}'),\"\n    echo \"    \"free_mb\": $(free -m | awk 'NR==2{print $4}'),\"\n    echo \"    \"usage_percent\": $(free | grep Mem | awk '{printf(\"%.1f\", ($3/$2) * 100)}')\"\n    echo \"  },\"\n    echo \"  \"disk\": {\"\n    echo \"    \"usage_percent\": $(df -h / | awk 'NR==2{print $5}' | sed 's/%//'),\"\n    echo \"    \"available_gb\": $(df -BG / | awk 'NR==2{print $4}' | sed 's/G//')\"\n    echo \"  },\"\n    echo \"  \"network\": {\"\n    echo \"    \"connections\": $(ss -tan | wc -l)\"\n    echo \"  }\"\n    echo \"}\"\n} > \"$METRICS_FILE\"\n\necho \"\u2713 Metrics collected: $METRICS_FILE\"\n",
    "#!/bin/bash\n# Monitor application uptime\n\nAPP_URL=\"${1:-http://localhost}\"\nCHECK_INTERVAL=\"${2:-60}\"\nLOG_FILE=\"/var/log/uptime-monitor.log\"\n\necho \"Monitoring: $APP_URL\"\necho \"Interval: ${CHECK_INTERVAL}s\"\necho \"Log: $LOG_FILE\"\necho \"Press Ctrl+C to stop\"\necho\n\ncheck_uptime() {\n    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')\n\n    response=$(curl -s -o /dev/null -w \"%{http_code}\" --max-time 10 \"$APP_URL\")\n\n    if [ \"$response\" = \"200\" ]; then\n        echo \"[$timestamp] \u2713 UP (HTTP $response)\" | tee -a \"$LOG_FILE\"\n        return 0\n    else\n        echo \"[$timestamp] \u2717 DOWN (HTTP $response)\" | tee -a \"$LOG_FILE\"\n\n        # Send alert\n        echo \"Application down: $APP_URL\" | mail -s \"Uptime Alert\" admin@example.com\n\n        return 1\n    fi\n}\n\nwhile true; do\n    check_uptime\n    sleep \"$CHECK_INTERVAL\"\ndone\n",
    "#!/bin/bash\n# Alert manager\n\nMESSAGE=\"${1}\"\nSEVERITY=\"${2:-INFO}\"\n\necho \"[$SEVERITY] $MESSAGE\" | tee -a /var/log/alerts.log\n\ncase $SEVERITY in\n    CRITICAL|ERROR)\n        echo \"$MESSAGE\" | mail -s \"[$SEVERITY] Alert\" admin@example.com\n        ;;\nesac\n",
    "#!/bin/bash\n# Metric dashboard generator\n\necho \"System Metrics Dashboard\"\necho \"========================\"\necho \"Date: $(date)\"\necho\n\necho \"CPU: $(top -bn1 | grep \"Cpu(s)\" | awk '{print $2}')\"\necho \"Memory: $(free -h | awk 'NR==2{print $3 \"/\" $2}')\"\necho \"Disk: $(df -h / | awk 'NR==2{print $5}')\"\necho \"Load: $(uptime | awk -F'load average:' '{print $2}')\"\n",
    "#!/bin/bash\n# Log rotation status\n\necho \"Log Rotation Status\"\necho \"===================\"\n\nlogrotate -d /etc/logrotate.conf 2>&1 | grep -E \"(rotating|compressing)\"\n",
    "#!/bin/bash\n# Service health dashboard\n\nSERVICES=(\"nginx\" \"mysql\" \"redis\")\n\necho \"Service Health Dashboard\"\necho \"=======================\"\n\nfor service in \"${SERVICES[@]}\"; do\n    if systemctl is-active --quiet \"$service\"; then\n        echo \"\u2713 $service: running\"\n    else\n        echo \"\u2717 $service: stopped\"\n    fi\ndone\n",
    "#!/bin/bash\n# Threshold alert system\n\nMETRIC_VALUE=$(get_metric_value)\nTHRESHOLD=80\n\nif [ \"$METRIC_VALUE\" -gt \"$THRESHOLD\" ]; then\n    echo \"Alert: Metric exceeded threshold\"\nfi\n",
    "#!/bin/bash\n# Custom metric exporter for Prometheus\n\necho \"# HELP system_cpu_usage CPU usage percentage\"\necho \"# TYPE system_cpu_usage gauge\"\necho \"system_cpu_usage $(top -bn1 | grep \"Cpu(s)\" | awk '{print $2}' | cut -d'%' -f1)\"\n",
    "#!/bin/bash\n# Log shipping to central server\n\nREMOTE_HOST=\"log-server.example.com\"\n\nrsync -az /var/log/ \"$REMOTE_HOST:/logs/$(hostname)/\"\n",
    "#!/bin/bash\n# Event correlation engine\n\ngrep -E \"(error|warning)\" /var/log/syslog |     awk '{print $1, $2, $5}' |     sort | uniq -c | sort -rn\n",
    "#!/bin/bash\n# Anomaly detector\n\nCURRENT=$(get_metric)\nBASELINE=$(cat /var/lib/baseline)\n\nDEVIATION=$(echo \"scale=2; ($CURRENT - $BASELINE) / $BASELINE * 100\" | bc)\n\nif (( $(echo \"$DEVIATION > 20\" | bc -l) )); then\n    echo \"Anomaly detected: ${DEVIATION}% deviation\"\nfi\n",
    "#!/bin/bash\n# Trending analyzer\n\nLOG_FILE=\"/var/log/metrics.log\"\n\necho \"7-Day Trend Analysis\"\necho \"====================\"\n\nfor day in {1..7}; do\n    date_str=$(date -d \"$day days ago\" +%Y-%m-%d)\n    count=$(grep \"$date_str\" \"$LOG_FILE\" | wc -l)\n    echo \"$date_str: $count events\"\ndone\n",
    "#!/bin/bash\n# Blue-green deployment script\n\nAPP_NAME=\"myapp\"\nNEW_VERSION=\"$1\"\nBLUE_PORT=8080\nGREEN_PORT=8081\nLB_CONFIG=\"/etc/nginx/sites-enabled/lb.conf\"\n\nif [ -z \"$NEW_VERSION\" ]; then\n    echo \"Usage: $0 <version>\"\n    exit 1\nfi\n\n# Detect current active environment\nCURRENT_PORT=$(grep -oP 'proxy_pass.*:\\K\\d+' \"$LB_CONFIG\")\n\nif [ \"$CURRENT_PORT\" = \"$BLUE_PORT\" ]; then\n    INACTIVE_PORT=$GREEN_PORT\n    INACTIVE_ENV=\"green\"\nelse\n    INACTIVE_PORT=$BLUE_PORT\n    INACTIVE_ENV=\"blue\"\nfi\n\necho \"Current: port $CURRENT_PORT\"\necho \"Deploying to: $INACTIVE_ENV (port $INACTIVE_PORT)\"\n\n# Deploy to inactive environment\ndeploy_to_inactive() {\n    docker pull \"$APP_NAME:$NEW_VERSION\"\n\n    docker stop \"$APP_NAME-$INACTIVE_ENV\" 2>/dev/null\n    docker rm \"$APP_NAME-$INACTIVE_ENV\" 2>/dev/null\n\n    docker run -d         --name \"$APP_NAME-$INACTIVE_ENV\"         -p \"$INACTIVE_PORT:8080\"         \"$APP_NAME:$NEW_VERSION\"\n\n    # Health check\n    for i in {1..30}; do\n        if curl -f \"http://localhost:$INACTIVE_PORT/health\" >/dev/null 2>&1; then\n            echo \"\u2713 Health check passed\"\n            return 0\n        fi\n        sleep 2\n    done\n\n    echo \"\u2717 Health check failed\"\n    return 1\n}\n\nswitch_traffic() {\n    # Update load balancer\n    sed -i \"s/proxy_pass.*:$CURRENT_PORT/proxy_pass http:\\/\\/localhost:$INACTIVE_PORT/\" \"$LB_CONFIG\"\n\n    # Reload nginx\n    nginx -t && nginx -s reload\n\n    echo \"\u2713 Traffic switched to $INACTIVE_ENV\"\n}\n\nif deploy_to_inactive; then\n    switch_traffic\n    echo \"Deployment successful!\"\nelse\n    echo \"Deployment failed!\"\n    exit 1\nfi\n",
    "#!/bin/bash\n# Rolling deployment script\n\nSERVERS=(\"app1\" \"app2\" \"app3\")\nNEW_VERSION=\"${1}\"\nDEPLOY_SCRIPT=\"/opt/deploy.sh\"\n\nif [ -z \"$NEW_VERSION\" ]; then\n    echo \"Usage: $0 <version>\"\n    exit 1\nfi\n\necho \"Rolling Deployment\"\necho \"==================\"\necho \"Version: $NEW_VERSION\"\necho \"Servers: ${SERVERS[*]}\"\necho\n\ndeploy_to_server() {\n    local server=$1\n\n    echo \"Deploying to $server...\"\n\n    # Remove from load balancer\n    echo \"  Draining $server...\"\n    ssh \"$server\" \"touch /var/www/maintenance\"\n    sleep 10\n\n    # Deploy\n    echo \"  Updating application...\"\n    ssh \"$server\" \"$DEPLOY_SCRIPT $NEW_VERSION\"\n\n    # Health check\n    echo \"  Running health check...\"\n    for i in {1..10}; do\n        if ssh \"$server\" \"curl -f http://localhost/health\" &>/dev/null; then\n            echo \"  \u2713 Health check passed\"\n\n            # Add back to load balancer\n            ssh \"$server\" \"rm /var/www/maintenance\"\n\n            echo \"  \u2713 $server deployment complete\"\n            return 0\n        fi\n        sleep 2\n    done\n\n    echo \"  \u2717 Health check failed\"\n    return 1\n}\n\nfor server in \"${SERVERS[@]}\"; do\n    if ! deploy_to_server \"$server\"; then\n        echo \"\u2717 Deployment failed on $server\"\n        echo \"Aborting rolling deployment\"\n        exit 1\n    fi\n\n    echo\n    sleep 5\ndone\n\necho \"\u2713 Rolling deployment complete\"\n",
    "#!/bin/bash\n# Complete deployment pipeline\n\nset -e\n\nPROJECT_DIR=\"${1:-.}\"\nENVIRONMENT=\"${2:-staging}\"\n\ncd \"$PROJECT_DIR\"\n\necho \"Deployment Pipeline\"\necho \"===================\"\necho \"Environment: $ENVIRONMENT\"\necho \"Commit: $(git rev-parse --short HEAD)\"\necho\n\nstage_build() {\n    echo \"=== Stage 1: Build ===\"\n\n    if [ -f \"package.json\" ]; then\n        npm ci\n        npm run build\n    elif [ -f \"Dockerfile\" ]; then\n        docker build -t \"app:$ENVIRONMENT\" .\n    fi\n\n    echo \"\u2713 Build complete\"\n}\n\nstage_test() {\n    echo\n    echo \"=== Stage 2: Test ===\"\n\n    if [ -f \"package.json\" ]; then\n        npm test\n    elif [ -f \"pytest.ini\" ]; then\n        pytest\n    fi\n\n    echo \"\u2713 Tests passed\"\n}\n\nstage_deploy() {\n    echo\n    echo \"=== Stage 3: Deploy ===\"\n\n    if [ \"$ENVIRONMENT\" = \"production\" ]; then\n        echo \"\u26a0 Deploying to PRODUCTION\"\n        read -p \"Continue? (yes/no) \" -r\n        [ \"$REPLY\" != \"yes\" ] && exit 1\n    fi\n\n    # Deploy based on environment\n    ./deploy.sh \"$ENVIRONMENT\"\n\n    echo \"\u2713 Deployment complete\"\n}\n\nstage_verify() {\n    echo\n    echo \"=== Stage 4: Verification ===\"\n\n    APP_URL=$(get_app_url \"$ENVIRONMENT\")\n\n    for i in {1..10}; do\n        if curl -f \"$APP_URL/health\" &>/dev/null; then\n            echo \"\u2713 Application is healthy\"\n            return 0\n        fi\n        sleep 5\n    done\n\n    echo \"\u2717 Verification failed\"\n    return 1\n}\n\n# Run pipeline\nstage_build\nstage_test\nstage_deploy\nstage_verify\n\necho\necho \"\u2713 Pipeline complete\"\n",
    "#!/bin/bash\n# Canary deployment\n\nNEW_VERSION=\"${1}\"\nCANARY_PERCENT=10\n\necho \"Deploying canary: $CANARY_PERCENT% traffic to $NEW_VERSION\"\n\n# Deploy canary\ndeploy_canary \"$NEW_VERSION\" \"$CANARY_PERCENT\"\n\n# Monitor for 10 minutes\nsleep 600\n\n# Check error rates\nif check_error_rate_acceptable; then\n    echo \"\u2713 Canary successful, rolling out to 100%\"\n    deploy_full \"$NEW_VERSION\"\nelse\n    echo \"\u2717 Canary failed, rolling back\"\n    rollback_canary\nfi\n",
    "#!/bin/bash\n# Zero-downtime deployment\n\necho \"Starting zero-downtime deployment...\"\n\n# Start new version alongside old\nstart_new_version\n\n# Gradually shift traffic\nshift_traffic 25\nsleep 60\nshift_traffic 50\nsleep 60\nshift_traffic 75\nsleep 60\nshift_traffic 100\n\n# Stop old version\nstop_old_version\n\necho \"\u2713 Zero-downtime deployment complete\"\n",
    "#!/bin/bash\n# Feature toggle deployment\n\nFEATURE=\"${1}\"\nENABLED=\"${2:-false}\"\n\necho \"Setting feature $FEATURE to $ENABLED\"\n\nupdate_feature_flag \"$FEATURE\" \"$ENABLED\"\n\necho \"\u2713 Feature toggle updated\"\n",
    "#!/bin/bash\n# A/B test deployment\n\nVARIANT_A=\"current\"\nVARIANT_B=\"${1}\"\n\necho \"Starting A/B test: $VARIANT_A vs $VARIANT_B\"\n\ndeploy_variant \"$VARIANT_B\"\nconfigure_traffic_split 50 50\n\necho \"\u2713 A/B test configured\"\n",
    "#!/bin/bash\n# Deployment health check\n\nAPP_URL=\"${1}\"\n\ncheck_endpoint() {\n    local endpoint=$1\n    curl -f \"$APP_URL$endpoint\" &>/dev/null\n}\n\necho \"Running deployment health checks...\"\n\ncheck_endpoint \"/health\" && echo \"\u2713 Health check passed\"\ncheck_endpoint \"/ready\" && echo \"\u2713 Ready check passed\"\ncheck_endpoint \"/metrics\" && echo \"\u2713 Metrics endpoint accessible\"\n\necho \"\u2713 All health checks passed\"\n",
    "#!/bin/bash\n# Configuration management\n\nENV=\"${1}\"\nCONFIG_FILE=\"/etc/app/config-${ENV}.yml\"\n\necho \"Applying configuration for: $ENV\"\n\ncp \"$CONFIG_FILE\" /etc/app/config.yml\nsystemctl reload app\n\necho \"\u2713 Configuration applied\"\n",
    "#!/bin/bash\n# Database migration during deployment\n\necho \"Running database migrations...\"\n\n# Backup\nbackup_database\n\n# Migrate\nrun_migrations\n\n# Verify\nverify_schema\n\necho \"\u2713 Migrations complete\"\n",
    "#!/bin/bash\n# Asset compilation and deployment\n\necho \"Compiling assets...\"\n\nnpm run build\naws s3 sync dist/ s3://assets-bucket/\n\necho \"\u2713 Assets deployed\"\n",
    "#!/bin/bash\n# Service mesh deployment\n\nSERVICE=\"${1}\"\n\nkubectl apply -f \"k8s/service-mesh/$SERVICE.yaml\"\n\necho \"\u2713 Service mesh configuration applied\"\n",
    "#!/bin/bash\n# Deployment notification\n\nENVIRONMENT=\"${1}\"\nVERSION=\"${2}\"\nSTATUS=\"${3}\"\n\nMESSAGE=\"Deployment to $ENVIRONMENT: $VERSION - $STATUS\"\n\n# Slack notification\ncurl -X POST -H 'Content-type: application/json'     --data \"{\"text\":\"$MESSAGE\"}\"     \"$SLACK_WEBHOOK_URL\"\n\necho \"\u2713 Notification sent\"\n",
    "#!/bin/bash\n# Pre-deployment checklist\n\necho \"Pre-Deployment Checklist\"\necho \"========================\"\n\ncheck_item \"Tests passing\" \"npm test\"\ncheck_item \"Linting clean\" \"npm run lint\"\ncheck_item \"Dependencies up to date\" \"npm outdated\"\ncheck_item \"Backup created\" \"test -f /backup/latest.tar.gz\"\n\necho \"\u2713 All checks passed\"\n",
    "#!/bin/bash\n# Post-deployment verification\n\nAPP_URL=\"${1}\"\n\necho \"Post-Deployment Verification\"\necho \"============================\"\n\n# Check health\ncurl -f \"$APP_URL/health\"\n\n# Run smoke tests\n./smoke-tests.sh \"$APP_URL\"\n\n# Verify database\nverify_database_connections\n\necho \"\u2713 Verification complete\"\n"
  ],
  "count": 100,
  "source": "generated_production"
}